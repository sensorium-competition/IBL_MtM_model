{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/turishcheva/u14642/miniconda/envs/ibl-fm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import (\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    "    load_dataset_builder,\n",
    ")\n",
    "from utils.dataset_utils import get_user_datasets, load_ibl_dataset, split_both_dataset\n",
    "from accelerate import Accelerator\n",
    "from loader.make_loader import make_loader\n",
    "from utils.utils import set_seed, dummy_load\n",
    "from utils.config_utils import config_from_kwargs, update_config\n",
    "from utils.dataset_utils import get_data_from_h5\n",
    "from models.ndt1 import NDT1\n",
    "from models.stpatch import STPatch\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from trainer.make import make_trainer\n",
    "import threading\n",
    "from loader.dataset import build_dataloader\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set to 42\n",
      "Create Dataloader.\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29623-4-9-Video-full/meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/turishcheva/u14642/miniconda/envs/ibl-fm/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29156-11-10-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29647-19-8-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29228-2-10-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29755-2-8-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29234-6-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29513-3-5-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29514-2-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29515-10-12-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29712-5-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29623-4-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29156-11-10-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29647-19-8-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29228-2-10-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29755-2-8-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29234-6-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29513-3-5-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29514-2-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29515-10-12-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29712-5-9-Video-full/meta.json\n",
      "Dataloader Created\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "kwargs = {\"model\": \"include:src/configs/ndt1_stitching_prompting.yaml\"}\n",
    "\n",
    "\n",
    "config = config_from_kwargs(kwargs)\n",
    "config = update_config(\"src/configs/ndt1_stitching_prompting.yaml\", config)\n",
    "config = update_config(\"src/configs/ssl_sessions_trainer.yaml\", config)\n",
    "\n",
    "# set seed for reproducibility\n",
    "set_seed(config.seed)\n",
    "\n",
    "with open('/user/turishcheva/u14642/IBL_MtM_model/src/configs/config.json', 'r') as file:\n",
    "    loader_config = json.load(file)\n",
    "\n",
    "print('Create Dataloader.')\n",
    "train_dataloader, val_dataloader = build_dataloader(loader_config)\n",
    "print('Dataloader Created')\n",
    "\n",
    "meta_data = {\"num_neurons\": [], \"num_sessions\": 0, \"eids\": []}\n",
    "for key, v in train_dataloader.loaders.items():\n",
    "    meta_data[\"num_neurons\"].append(next(iter(v))['responses'].shape[-1])\n",
    "    meta_data[\"num_sessions\"] += 1\n",
    "    meta_data[\"eids\"].append(key)\n",
    "\n",
    "num_sessions = len(meta_data[\"eids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/user/turishcheva/u14642/IBL_MtM_model/model_best.pt', weights_only=False, map_location=torch.device('cpu'))['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDT1(\n",
       "  (encoder): NeuralEncoder(\n",
       "    (masker): Masker()\n",
       "    (stitcher): NeuralStitcher(\n",
       "      (stitcher_dict): ModuleDict(\n",
       "        (7671): Linear(in_features=7671, out_features=668, bias=True)\n",
       "        (7495): Linear(in_features=7495, out_features=668, bias=True)\n",
       "        (8122): Linear(in_features=8122, out_features=668, bias=True)\n",
       "        (8202): Linear(in_features=8202, out_features=668, bias=True)\n",
       "        (7440): Linear(in_features=7440, out_features=668, bias=True)\n",
       "        (7908): Linear(in_features=7908, out_features=668, bias=True)\n",
       "        (7863): Linear(in_features=7863, out_features=668, bias=True)\n",
       "        (8285): Linear(in_features=8285, out_features=668, bias=True)\n",
       "        (7939): Linear(in_features=7939, out_features=668, bias=True)\n",
       "        (7928): Linear(in_features=7928, out_features=668, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (embedder): NeuralEmbeddingLayer(\n",
       "      (embed_spikes): Linear(in_features=668, out_features=1336, bias=True)\n",
       "      (projection): Linear(in_features=1336, out_features=512, bias=True)\n",
       "      (act): Softsign()\n",
       "      (embed_pos): Embedding(100, 512)\n",
       "      (embed_prompt): Embedding(4, 512)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-4): 5 x NeuralEncoderLayer(\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): NeuralAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): NeuralMLP(\n",
       "          (up_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (down_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (out_proj): NeuralFactorsProjection(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stitch_decoder): StitchDecoder(\n",
       "    (stitch_decoder_dict): ModuleDict(\n",
       "      (7671): Linear(in_features=512, out_features=7671, bias=True)\n",
       "      (7495): Linear(in_features=512, out_features=7495, bias=True)\n",
       "      (8122): Linear(in_features=512, out_features=8122, bias=True)\n",
       "      (8202): Linear(in_features=512, out_features=8202, bias=True)\n",
       "      (7440): Linear(in_features=512, out_features=7440, bias=True)\n",
       "      (7908): Linear(in_features=512, out_features=7908, bias=True)\n",
       "      (7863): Linear(in_features=512, out_features=7863, bias=True)\n",
       "      (8285): Linear(in_features=512, out_features=8285, bias=True)\n",
       "      (7939): Linear(in_features=512, out_features=7939, bias=True)\n",
       "      (7928): Linear(in_features=512, out_features=7928, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=668, bias=True)\n",
       "  )\n",
       "  (loss_fn): PoissonNLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - should be True on a retrained model!\n",
    "model.encoder.embedder.use_session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero is masked out, 1 is kept\n",
    "mask = ... ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# TODO - do I really need this line?\n",
    "masking_mode = 'neuron' if model.use_prompt else model.encoder.masker.mode\n",
    "model.encoder.mask = False\n",
    "\n",
    "\n",
    "\n",
    "B, T, S = batch[1]['responses'].shape\n",
    "\n",
    "batched_mask = mask.repeat(B,1)\n",
    "\n",
    "# NDT1Output(\n",
    "#     loss=loss,\n",
    "#     n_examples=n_examples,\n",
    "#     preds=outputs,\n",
    "#     targets=targets\n",
    "# )\n",
    "\n",
    "outputs = model(\n",
    "    (batched_mask * batch[1]['responses']).to(torch.float32).to(device), # https://github.com/colehurwitz/IBL_MtM_model/blob/main/src/utils/eval_utils.py#L1109\n",
    "    time_attn_mask=torch.ones(B, T).to(torch.int64).to(device),\n",
    "    space_attn_mask=torch.ones(B, S).to(torch.int64).to(device),\n",
    "    spikes_timestamps=torch.arange(T).to(torch.int64).repeat(B,1).to(device), \n",
    "    spikes_spacestamps=torch.arange(S).to(torch.int64).repeat(B,1).to(device), \n",
    "    targets = float('nan')*torch.ones(B,1).to(torch.int64),\n",
    "    neuron_regions=[['V1']*B]*S,\n",
    "    eval_mask= (1- batched_mask).to(device), # https://github.com/colehurwitz/IBL_MtM_model/blob/main/src/utils/eval_utils.py#L1111\n",
    "    masking_mode = masking_mode, # TODO - double check this\n",
    "    num_neuron= S ,\n",
    "    eid=batch[0] # session key\n",
    ")\n",
    "preds = outputs.preds\n",
    "targets = outputs.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some helpful copypaste of code for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = torch.ones(spike_data.shape).to(torch.int64).to(spike_data.device)\n",
    "# masked elements - are zeros?\n",
    "# {\"spikes\": spike_data_masked, \"heldout_idxs\": hd, \"eval_mask\": 1-mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/colehurwitz/IBL_MtM_model/blob/main/src/models/ndt1.py#L653C3-L672C1\n",
    "#   def forward(\n",
    "#         self, \n",
    "#         spikes:           torch.FloatTensor,  # (bs, seq_len, n_channels)\n",
    "#         time_attn_mask:      torch.LongTensor,   # (bs, seq_len)\n",
    "#         space_attn_mask:      torch.LongTensor,   # (bs, seq_len)\n",
    "#         spikes_timestamps: torch.LongTensor,   # (bs, seq_len)\n",
    "#         spikes_spacestamps: torch.LongTensor,   # (bs, seq_len)\n",
    "#         targets:          Optional[torch.FloatTensor] = None,  # (bs, tar_len)\n",
    "#         spikes_lengths:   Optional[torch.LongTensor] = None,   # (bs) \n",
    "#         targets_lengths:  Optional[torch.LongTensor] = None,   # (bs)\n",
    "#         block_idx:        Optional[torch.LongTensor] = None,   # (bs)\n",
    "#         date_idx:         Optional[torch.LongTensor] = None,   # (bs)\n",
    "#         neuron_regions:   Optional[torch.LongTensor] = None,   # (bs, n_channels)\n",
    "#         masking_mode:     Optional[str] = None,\n",
    "#         spike_augmentation: Optional[bool] = False,\n",
    "#         eval_mask:        Optional[torch.LongTensor] = None,\n",
    "#         num_neuron:       Optional[torch.LongTensor] = None,\n",
    "#         eid:              Optional[str] = None,\n",
    "#     ) -> NDT1Output:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _forward_model_outputs_experanto(self, batch, masking_mode):\n",
    "#         B, T, S = batch[1]['responses'].shape\n",
    "#         return self.model(\n",
    "#             batch[1]['responses'].to(torch.float32).to(self.accelerator.device), \n",
    "#             time_attn_mask=torch.ones(B, T).to(torch.int64).to(self.accelerator.device),\n",
    "#             space_attn_mask=torch.ones(B, S).to(torch.int64).to(self.accelerator.device),\n",
    "#             spikes_timestamps=torch.arange(T).to(torch.int64).repeat(B,1).to(self.accelerator.device),\n",
    "#             spikes_spacestamps=torch.arange(S).to(torch.int64).repeat(B,1).to(self.accelerator.device),\n",
    "#             targets = float('nan')*torch.ones(B,1).to(torch.int64),\n",
    "#             neuron_regions=[['V1']*B]*S,\n",
    "#             masking_mode=masking_mode,\n",
    "#             spike_augmentation=self.config.data.spike_augmentation,\n",
    "#             num_neuron=S,\n",
    "#             eid='test-test-test'  # each batch consists of data from the same eid\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/colehurwitz/IBL_MtM_model/blob/main/src/utils/eval_utils.py#L213-L245\n",
    "# if counter <= tot_num_neurons:\n",
    "#     mask_result = heldout_mask(\n",
    "#         batch['spikes_data'].clone(),\n",
    "#         mode='manual',\n",
    "#         heldout_idxs=np.array([n_i+i])\n",
    "#     )\n",
    "#     mask_spikes_lst.append(mask_result['spikes'])\n",
    "#     eval_mask_lst.append(mask_result['eval_mask'])\n",
    "#     gt_spikes_lst.append(gt_spike_data)\n",
    "#     time_attn_mask_lst.append(batch['time_attn_mask'])\n",
    "#     space_attn_mask_lst.append(batch['space_attn_mask'])\n",
    "#     spikes_timestamps_lst.append(batch['spikes_timestamps'])\n",
    "#     spikes_spacestamps_lst.append(batch['spikes_spacestamps'])\n",
    "#     targets_lst.append(batch['target'])\n",
    "#     neuron_regions_lst.append(batch['neuron_regions'])\n",
    "# else:\n",
    "#     break\n",
    "\n",
    "# masking_mode = 'neuron' if model.use_prompt else model.encoder.masker.mode\n",
    "# model.encoder.mask = False\n",
    "\n",
    "# outputs = model(\n",
    "#     torch.cat(mask_spikes_lst, 0),\n",
    "#     time_attn_mask=torch.cat(time_attn_mask_lst, 0),\n",
    "#     space_attn_mask=torch.cat(space_attn_mask_lst, 0),\n",
    "#     spikes_timestamps=torch.cat(spikes_timestamps_lst, 0), \n",
    "#     spikes_spacestamps=torch.cat(spikes_spacestamps_lst, 0), \n",
    "#     targets = torch.cat(targets_lst, 0),\n",
    "#     neuron_regions=np.stack(neuron_regions_lst),\n",
    "#     eval_mask=torch.cat(eval_mask_lst, 0),\n",
    "#     masking_mode = masking_mode,\n",
    "#     num_neuron=batch['spikes_data'].shape[2],\n",
    "#     eid=batch['eid'][0]  # each batch consists of data from the same eid\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibl-fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
