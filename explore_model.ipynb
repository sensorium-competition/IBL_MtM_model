{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/turishcheva/u14642/miniconda/envs/ibl-fm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import (\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    "    load_dataset_builder,\n",
    ")\n",
    "from utils.dataset_utils import get_user_datasets, load_ibl_dataset, split_both_dataset\n",
    "from accelerate import Accelerator\n",
    "from loader.make_loader import make_loader\n",
    "from utils.utils import set_seed, dummy_load\n",
    "from utils.config_utils import config_from_kwargs, update_config\n",
    "from utils.dataset_utils import get_data_from_h5\n",
    "from models.ndt1 import NDT1\n",
    "from models.stpatch import STPatch\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from trainer.make import make_trainer\n",
    "import threading\n",
    "from loader.dataset import build_dataloader\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set to 42\n",
      "Create Dataloader.\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29623-4-9-Video-full/meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/turishcheva/u14642/miniconda/envs/ibl-fm/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29156-11-10-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29647-19-8-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29228-2-10-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29755-2-8-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29234-6-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29513-3-5-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29514-2-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29515-10-12-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29712-5-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29623-4-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29156-11-10-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29647-19-8-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29228-2-10-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29755-2-8-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29234-6-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29513-3-5-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29514-2-9-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29515-10-12-Video-full/meta.json\n",
      "No metadata file found at /mnt/vast-react/projects/neural_foundation_model/dynamic29712-5-9-Video-full/meta.json\n",
      "Dataloader Created\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "kwargs = {\"model\": \"include:src/configs/ndt1_stitching_prompting.yaml\"}\n",
    "\n",
    "\n",
    "config = config_from_kwargs(kwargs)\n",
    "config = update_config(\"src/configs/ndt1_stitching_prompting.yaml\", config)\n",
    "config = update_config(\"src/configs/ssl_sessions_trainer.yaml\", config)\n",
    "\n",
    "# set seed for reproducibility\n",
    "set_seed(config.seed)\n",
    "\n",
    "with open('/user/turishcheva/u14642/IBL_MtM_model/src/configs/config.json', 'r') as file:\n",
    "    loader_config = json.load(file)\n",
    "\n",
    "print('Create Dataloader.')\n",
    "train_dataloader, val_dataloader = build_dataloader(loader_config)\n",
    "print('Dataloader Created')\n",
    "\n",
    "meta_data = {\"num_neurons\": [], \"num_sessions\": 0, \"eids\": []}\n",
    "for key, v in train_dataloader.loaders.items():\n",
    "    meta_data[\"num_neurons\"].append(next(iter(v))['responses'].shape[-1])\n",
    "    meta_data[\"num_sessions\"] += 1\n",
    "    meta_data[\"eids\"].append(key)\n",
    "\n",
    "num_sessions = len(meta_data[\"eids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = ['dynamic29623-4-9-Video-full', 'dynamic29156-11-10-Video-full', 'dynamic29647-19-8-Video-full',\n",
    "# 'dynamic29228-2-10-Video-full', 'dynamic29755-2-8-Video-full', 'dynamic29234-6-9-Video-full',\n",
    "# 'dynamic29513-3-5-Video-full', 'dynamic29514-2-9-Video-full', 'dynamic29515-10-12-Video-full', 'dynamic29712-5-9-Video-full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make log dir\n",
    "log_dir = os.path.join(\n",
    "    config.dirs.log_dir,\n",
    "    \"train\",\n",
    "    \"num_session_{}\".format(num_sessions),\n",
    "    \"model_{}\".format(config.model.model_class),\n",
    "    \"method_{}\".format(config.method.model_kwargs.method_name),\n",
    "    \"mask_{}\".format(config.encoder.masker.mode),\n",
    "    \"stitch_{}\".format(config.encoder.stitching),\n",
    ")\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "\n",
    "# # make the dataloader\n",
    "# train_dataloader = make_loader(\n",
    "#     train_dataset,\n",
    "#     target=config.data.target,\n",
    "#     load_meta=config.data.load_meta,\n",
    "#     batch_size=config.training.train_batch_size,\n",
    "#     pad_to_right=True,\n",
    "#     pad_value=-1.0,\n",
    "#     max_time_length=config.data.max_time_length,\n",
    "#     max_space_length=config.data.max_space_length,\n",
    "#     dataset_name=config.data.dataset_name,\n",
    "#     sort_by_depth=config.data.sort_by_depth,\n",
    "#     sort_by_region=config.data.sort_by_region,\n",
    "#     stitching=config.encoder.stitching,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "# # /mnt/vast-react/projects/agsinz_foundation_model_brain/goirik/IBL_MtM_model/src/loader/base.py _preprocess_ibl_dataset\n",
    "# # return {\n",
    "# #     \"spikes_data\": binned_spikes_data,\n",
    "# #     \"time_attn_mask\": time_attn_mask,\n",
    "# #     \"space_attn_mask\": space_attn_mask,\n",
    "# #     \"spikes_timestamps\": spikes_timestamps,\n",
    "# #     \"spikes_spacestamps\": spikes_spacestamps,\n",
    "# #     \"target\": target_behavior,\n",
    "# #     \"neuron_depths\": neuron_depths, \n",
    "# #     \"neuron_regions\": list(neuron_regions),\n",
    "# #     \"eid\": data['eid']\n",
    "# # }\n",
    "\n",
    "# val_dataloader = make_loader(\n",
    "#     val_dataset,\n",
    "#     target=config.data.target,\n",
    "#     load_meta=config.data.load_meta,\n",
    "#     batch_size=config.training.test_batch_size,\n",
    "#     pad_to_right=True,\n",
    "#     pad_value=-1.0,\n",
    "#     max_time_length=config.data.max_time_length,\n",
    "#     max_space_length=config.data.max_space_length,\n",
    "#     dataset_name=config.data.dataset_name,\n",
    "#     sort_by_depth=config.data.sort_by_depth,\n",
    "#     sort_by_region=config.data.sort_by_region,\n",
    "#     stitching=config.encoder.stitching,\n",
    "#     shuffle=False,\n",
    "# )\n",
    "\n",
    "# Initialize the accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# load model\n",
    "NAME2MODEL = {\"NDT1\": NDT1, \"STPatch\": STPatch}\n",
    "\n",
    "config = update_config(config, meta_data)\n",
    "model_class = NAME2MODEL[config.model.model_class]\n",
    "model = model_class(config.model, **config.method.model_kwargs, **meta_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDT1(\n",
       "  (encoder): NeuralEncoder(\n",
       "    (masker): Masker()\n",
       "    (stitcher): NeuralStitcher(\n",
       "      (stitcher_dict): ModuleDict(\n",
       "        (7908): Linear(in_features=7908, out_features=668, bias=True)\n",
       "        (7440): Linear(in_features=7440, out_features=668, bias=True)\n",
       "        (8202): Linear(in_features=8202, out_features=668, bias=True)\n",
       "        (7928): Linear(in_features=7928, out_features=668, bias=True)\n",
       "        (8122): Linear(in_features=8122, out_features=668, bias=True)\n",
       "        (8285): Linear(in_features=8285, out_features=668, bias=True)\n",
       "        (7671): Linear(in_features=7671, out_features=668, bias=True)\n",
       "        (7495): Linear(in_features=7495, out_features=668, bias=True)\n",
       "        (7863): Linear(in_features=7863, out_features=668, bias=True)\n",
       "        (7939): Linear(in_features=7939, out_features=668, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (embedder): NeuralEmbeddingLayer(\n",
       "      (embed_spikes): Linear(in_features=668, out_features=1336, bias=True)\n",
       "      (projection): Linear(in_features=1336, out_features=512, bias=True)\n",
       "      (act): Softsign()\n",
       "      (embed_pos): Embedding(100, 512)\n",
       "      (embed_prompt): Embedding(4, 512)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-4): 5 x NeuralEncoderLayer(\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): NeuralAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): NeuralMLP(\n",
       "          (up_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (down_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (out_proj): NeuralFactorsProjection(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stitch_decoder): StitchDecoder(\n",
       "    (stitch_decoder_dict): ModuleDict(\n",
       "      (7908): Linear(in_features=512, out_features=7908, bias=True)\n",
       "      (7440): Linear(in_features=512, out_features=7440, bias=True)\n",
       "      (8202): Linear(in_features=512, out_features=8202, bias=True)\n",
       "      (7928): Linear(in_features=512, out_features=7928, bias=True)\n",
       "      (8122): Linear(in_features=512, out_features=8122, bias=True)\n",
       "      (8285): Linear(in_features=512, out_features=8285, bias=True)\n",
       "      (7671): Linear(in_features=512, out_features=7671, bias=True)\n",
       "      (7495): Linear(in_features=512, out_features=7495, bias=True)\n",
       "      (7863): Linear(in_features=512, out_features=7863, bias=True)\n",
       "      (7939): Linear(in_features=512, out_features=7939, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=668, bias=True)\n",
       "  )\n",
       "  (loss_fn): PoissonNLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/user/turishcheva/u14642/IBL_MtM_model/model_best.pt', weights_only=False)['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('/user/turishcheva/u14642/IBL_MtM_model/model_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDT1(\n",
       "  (encoder): NeuralEncoder(\n",
       "    (masker): Masker()\n",
       "    (stitcher): NeuralStitcher(\n",
       "      (stitcher_dict): ModuleDict(\n",
       "        (7671): Linear(in_features=7671, out_features=668, bias=True)\n",
       "        (7495): Linear(in_features=7495, out_features=668, bias=True)\n",
       "        (8122): Linear(in_features=8122, out_features=668, bias=True)\n",
       "        (8202): Linear(in_features=8202, out_features=668, bias=True)\n",
       "        (7440): Linear(in_features=7440, out_features=668, bias=True)\n",
       "        (7908): Linear(in_features=7908, out_features=668, bias=True)\n",
       "        (7863): Linear(in_features=7863, out_features=668, bias=True)\n",
       "        (8285): Linear(in_features=8285, out_features=668, bias=True)\n",
       "        (7939): Linear(in_features=7939, out_features=668, bias=True)\n",
       "        (7928): Linear(in_features=7928, out_features=668, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (embedder): NeuralEmbeddingLayer(\n",
       "      (embed_spikes): Linear(in_features=668, out_features=1336, bias=True)\n",
       "      (projection): Linear(in_features=1336, out_features=512, bias=True)\n",
       "      (act): Softsign()\n",
       "      (embed_pos): Embedding(100, 512)\n",
       "      (embed_prompt): Embedding(4, 512)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-4): 5 x NeuralEncoderLayer(\n",
       "        (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): NeuralAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): NeuralMLP(\n",
       "          (up_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (down_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (out_proj): NeuralFactorsProjection(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stitch_decoder): StitchDecoder(\n",
       "    (stitch_decoder_dict): ModuleDict(\n",
       "      (7671): Linear(in_features=512, out_features=7671, bias=True)\n",
       "      (7495): Linear(in_features=512, out_features=7495, bias=True)\n",
       "      (8122): Linear(in_features=512, out_features=8122, bias=True)\n",
       "      (8202): Linear(in_features=512, out_features=8202, bias=True)\n",
       "      (7440): Linear(in_features=512, out_features=7440, bias=True)\n",
       "      (7908): Linear(in_features=512, out_features=7908, bias=True)\n",
       "      (7863): Linear(in_features=512, out_features=7863, bias=True)\n",
       "      (8285): Linear(in_features=512, out_features=8285, bias=True)\n",
       "      (7939): Linear(in_features=512, out_features=7939, bias=True)\n",
       "      (7928): Linear(in_features=512, out_features=7928, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=668, bias=True)\n",
       "  )\n",
       "  (loss_fn): PoissonNLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.encoder.masker.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssl'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neuron', True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.masker.mode, model.encoder.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralEncoder(\n",
       "  (masker): Masker()\n",
       "  (stitcher): NeuralStitcher(\n",
       "    (stitcher_dict): ModuleDict(\n",
       "      (7671): Linear(in_features=7671, out_features=668, bias=True)\n",
       "      (7495): Linear(in_features=7495, out_features=668, bias=True)\n",
       "      (8122): Linear(in_features=8122, out_features=668, bias=True)\n",
       "      (8202): Linear(in_features=8202, out_features=668, bias=True)\n",
       "      (7440): Linear(in_features=7440, out_features=668, bias=True)\n",
       "      (7908): Linear(in_features=7908, out_features=668, bias=True)\n",
       "      (7863): Linear(in_features=7863, out_features=668, bias=True)\n",
       "      (8285): Linear(in_features=8285, out_features=668, bias=True)\n",
       "      (7939): Linear(in_features=7939, out_features=668, bias=True)\n",
       "      (7928): Linear(in_features=7928, out_features=668, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (embedder): NeuralEmbeddingLayer(\n",
       "    (embed_spikes): Linear(in_features=668, out_features=1336, bias=True)\n",
       "    (projection): Linear(in_features=1336, out_features=512, bias=True)\n",
       "    (act): Softsign()\n",
       "    (embed_pos): Embedding(100, 512)\n",
       "    (embed_prompt): Embedding(4, 512)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0-4): 5 x NeuralEncoderLayer(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): NeuralAttention(\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.4, inplace=False)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): NeuralMLP(\n",
       "        (up_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (act): GELUActivation()\n",
       "        (down_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_proj): NeuralFactorsProjection(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking entry point https://github.com/sensorium-competition/IBL_MtM_model/blob/10e84fcecea45e2a3e8c51797372df06e7fca40d/src/models/ndt1.py#L483-L500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, -1, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.context_forward, model.encoder.context_backward, model.encoder.max_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.ndt1 import create_context_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_mask = create_context_mask(model.encoder.context_forward, model.encoder.context_backward, model.encoder.max_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 100]), tensor(10000))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_mask.shape, context_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = accelerator.prepare(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.optimizer.lr,\n",
    "    weight_decay=config.optimizer.wd,\n",
    "    eps=config.optimizer.eps,\n",
    ")\n",
    "lr_scheduler = OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    total_steps=config.training.num_epochs * len(train_dataloader) // config.optimizer.gradient_accumulation_steps,\n",
    "    max_lr=config.optimizer.lr,\n",
    "    pct_start=config.optimizer.warmup_pct,\n",
    "    div_factor=config.optimizer.div_factor,\n",
    ")\n",
    "\n",
    "trainer_kwargs = {\n",
    "    \"log_dir\": log_dir,\n",
    "    \"accelerator\": accelerator,\n",
    "    \"lr_scheduler\": lr_scheduler,\n",
    "    \"config\": config,\n",
    "    \"stitching\": config.encoder.stitching,\n",
    "}\n",
    "\n",
    "trainer = make_trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    **trainer_kwargs,\n",
    "    **meta_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<experanto.utils.LongCycler at 0x150bd6c528f0>, 'neuron')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataloader, trainer.masking_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "batch = next(iter(trainer.train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('29623-4-9',\n",
       " {'screen': tensor([[[[[ 1.1405e+00,  1.1519e+00,  1.1912e+00,  ...,  3.5917e-01,\n",
       "               3.3671e-01,  3.1952e-01],\n",
       "             [ 1.2385e+00,  1.2484e+00,  1.2758e+00,  ...,  3.6289e-01,\n",
       "               3.4176e-01,  3.2940e-01],\n",
       "             [ 1.4237e+00,  1.3995e+00,  1.3718e+00,  ...,  3.6092e-01,\n",
       "               3.3987e-01,  3.3723e-01],\n",
       "             ...,\n",
       "             [-7.7821e-01, -8.1287e-01, -6.0339e-01,  ..., -5.0364e-01,\n",
       "              -6.3979e-01, -7.9896e-01],\n",
       "             [-6.6414e-01, -6.7335e-01, -4.7492e-01,  ..., -2.4066e-01,\n",
       "              -3.8683e-01, -5.9326e-01],\n",
       "             [-3.3078e-01, -4.5662e-01, -4.4365e-01,  ..., -2.3831e-01,\n",
       "              -2.6302e-01, -2.9906e-01]],\n",
       "  \n",
       "            [[ 1.1237e+00,  1.1498e+00,  1.2020e+00,  ...,  3.5126e-01,\n",
       "               3.2882e-01,  3.1952e-01],\n",
       "             [ 1.2079e+00,  1.2285e+00,  1.2771e+00,  ...,  3.6012e-01,\n",
       "               3.3695e-01,  3.2810e-01],\n",
       "             [ 1.3534e+00,  1.3540e+00,  1.3598e+00,  ...,  3.5447e-01,\n",
       "               3.3861e-01,  3.2927e-01],\n",
       "             ...,\n",
       "             [-5.6843e-01, -5.6441e-01, -5.8408e-01,  ..., -5.9611e-01,\n",
       "              -6.5216e-01, -6.8609e-01],\n",
       "             [-7.7661e-01, -6.0337e-01, -4.8405e-01,  ..., -3.6210e-01,\n",
       "              -5.3122e-01, -7.1061e-01],\n",
       "             [-7.5928e-01, -5.2664e-01, -3.8132e-01,  ..., -2.0527e-01,\n",
       "              -3.1138e-01, -4.9886e-01]],\n",
       "  \n",
       "            [[ 1.1135e+00,  1.1334e+00,  1.1751e+00,  ...,  3.2797e-01,\n",
       "               3.0434e-01,  2.9630e-01],\n",
       "             [ 1.1355e+00,  1.1683e+00,  1.2252e+00,  ...,  3.5714e-01,\n",
       "               3.3433e-01,  3.2845e-01],\n",
       "             [ 1.2161e+00,  1.2597e+00,  1.3012e+00,  ...,  3.5670e-01,\n",
       "               3.3554e-01,  3.4847e-01],\n",
       "             ...,\n",
       "             [-7.8122e-01, -6.5239e-01, -4.5734e-01,  ..., -1.4516e-01,\n",
       "              -4.5656e-01, -2.9000e-01],\n",
       "             [-7.6457e-01, -6.7061e-01, -5.2576e-01,  ..., -5.4724e-01,\n",
       "              -6.2853e-01, -5.4308e-01],\n",
       "             [-6.6561e-01, -6.5653e-01, -6.3273e-01,  ..., -4.8831e-01,\n",
       "              -6.3472e-01, -7.6455e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.2056e+00,  1.2404e+00,  1.2969e+00,  ...,  4.4422e-01,\n",
       "               4.1471e-01,  3.9586e-01],\n",
       "             [ 1.2997e+00,  1.3169e+00,  1.3621e+00,  ...,  5.0650e-01,\n",
       "               4.8100e-01,  4.5387e-01],\n",
       "             [ 1.4795e+00,  1.4628e+00,  1.5208e+00,  ...,  5.8344e-01,\n",
       "               5.4744e-01,  5.1712e-01],\n",
       "             ...,\n",
       "             [-5.9280e-01, -6.7683e-01, -6.5422e-01,  ..., -2.4185e-01,\n",
       "              -2.9245e-01, -4.0153e-01],\n",
       "             [-6.9858e-01, -6.6105e-01, -5.6642e-01,  ..., -1.3743e-01,\n",
       "              -3.3390e-01, -4.6373e-01],\n",
       "             [-5.5427e-01, -4.4495e-01, -3.6899e-01,  ..., -2.0879e-01,\n",
       "              -3.2426e-01, -4.4204e-01]],\n",
       "  \n",
       "            [[ 1.1752e+00,  1.2159e+00,  1.2721e+00,  ...,  4.0762e-01,\n",
       "               3.7176e-01,  3.5962e-01],\n",
       "             [ 1.2711e+00,  1.2957e+00,  1.3374e+00,  ...,  4.6710e-01,\n",
       "               4.3547e-01,  4.0760e-01],\n",
       "             [ 1.4318e+00,  1.4147e+00,  1.4315e+00,  ...,  5.4026e-01,\n",
       "               5.1918e-01,  5.0214e-01],\n",
       "             ...,\n",
       "             [-6.4521e-01, -5.6853e-01, -5.2781e-01,  ..., -1.0291e-03,\n",
       "              -2.9162e-02, -4.9238e-02],\n",
       "             [-6.0915e-01, -6.1571e-01, -5.8800e-01,  ..., -2.0418e-01,\n",
       "              -1.9338e-01, -1.7617e-01],\n",
       "             [-6.8235e-01, -7.2622e-01, -6.3012e-01,  ..., -1.7180e-01,\n",
       "              -2.4431e-01, -2.8840e-01]],\n",
       "  \n",
       "            [[ 1.1282e+00,  1.1806e+00,  1.2414e+00,  ...,  3.3638e-01,\n",
       "               3.1403e-01,  2.8494e-01],\n",
       "             [ 1.2292e+00,  1.2648e+00,  1.3056e+00,  ...,  4.0561e-01,\n",
       "               3.7536e-01,  3.4410e-01],\n",
       "             [ 1.3826e+00,  1.3518e+00,  1.3675e+00,  ...,  4.8131e-01,\n",
       "               4.5502e-01,  4.2682e-01],\n",
       "             ...,\n",
       "             [-5.8807e-01, -5.1460e-01, -3.3017e-01,  ...,  4.0991e-02,\n",
       "               1.1971e-01,  4.7235e-02],\n",
       "             [-6.2519e-01, -5.5927e-01, -5.4406e-01,  ..., -5.5666e-02,\n",
       "              -6.6509e-02,  4.3667e-03],\n",
       "             [-6.2578e-01, -6.2179e-01, -5.9674e-01,  ..., -1.3715e-01,\n",
       "              -6.2947e-03, -6.1281e-02]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-5.2023e-01, -3.3853e-01, -2.6857e-01,  ..., -8.1557e-01,\n",
       "              -7.9864e-01, -7.8973e-01],\n",
       "             [-5.9109e-01, -4.6872e-01, -3.8888e-01,  ..., -7.0687e-01,\n",
       "              -6.8749e-01, -6.7320e-01],\n",
       "             [-6.3572e-01, -5.1127e-01, -4.5726e-01,  ..., -6.2196e-01,\n",
       "              -6.1106e-01, -6.1081e-01],\n",
       "             ...,\n",
       "             [-7.7213e-01, -6.0782e-01, -6.4593e-01,  ..., -6.0936e-01,\n",
       "              -5.9482e-01, -6.0432e-01],\n",
       "             [-5.7661e-01, -5.4151e-01, -6.9734e-01,  ..., -6.3375e-01,\n",
       "              -5.7172e-01, -5.8035e-01],\n",
       "             [-4.4827e-01, -5.4693e-01, -6.9945e-01,  ..., -6.4419e-01,\n",
       "              -6.0914e-01, -6.0209e-01]],\n",
       "  \n",
       "            [[-5.2023e-01, -3.4189e-01, -2.6429e-01,  ..., -8.9098e-01,\n",
       "              -8.2203e-01, -8.3390e-01],\n",
       "             [-5.8910e-01, -4.7010e-01, -3.8380e-01,  ..., -7.7956e-01,\n",
       "              -7.1343e-01, -7.1294e-01],\n",
       "             [-6.1511e-01, -4.7489e-01, -4.2476e-01,  ..., -6.5648e-01,\n",
       "              -6.2275e-01, -6.3591e-01],\n",
       "             ...,\n",
       "             [-8.2906e-01, -7.5698e-01, -7.0309e-01,  ..., -5.4519e-01,\n",
       "              -5.2031e-01, -6.5130e-01],\n",
       "             [-7.6887e-01, -7.5004e-01, -7.2889e-01,  ..., -6.1283e-01,\n",
       "              -5.8828e-01, -6.3306e-01],\n",
       "             [-7.3933e-01, -7.5185e-01, -7.3402e-01,  ..., -6.3866e-01,\n",
       "              -5.9920e-01, -6.0214e-01]],\n",
       "  \n",
       "            [[-5.1064e-01, -2.8438e-01, -1.8398e-01,  ..., -7.3916e-01,\n",
       "              -9.1443e-01, -8.7168e-01],\n",
       "             [-5.8407e-01, -4.4137e-01, -3.6552e-01,  ..., -6.9812e-01,\n",
       "              -8.9922e-01, -7.9948e-01],\n",
       "             [-6.1423e-01, -4.7437e-01, -4.2339e-01,  ..., -5.5292e-01,\n",
       "              -7.9851e-01, -7.1785e-01],\n",
       "             ...,\n",
       "             [-8.0026e-01, -7.5644e-01, -6.9423e-01,  ..., -6.0160e-01,\n",
       "              -5.5977e-01, -4.7809e-01],\n",
       "             [-7.6509e-01, -7.4814e-01, -7.2294e-01,  ..., -5.2959e-01,\n",
       "              -5.6117e-01, -5.4197e-01],\n",
       "             [-7.5913e-01, -7.4818e-01, -7.1484e-01,  ..., -5.0619e-01,\n",
       "              -5.3326e-01, -5.8849e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.2334e+00, -1.1082e+00, -1.0194e+00,  ..., -1.2471e+00,\n",
       "              -1.2181e+00, -1.2648e+00],\n",
       "             [-1.2467e+00, -9.0936e-01, -4.5058e-01,  ..., -1.2687e+00,\n",
       "              -1.2408e+00, -1.1953e+00],\n",
       "             [-1.0549e+00, -7.5401e-01, -9.5632e-01,  ..., -1.2646e+00,\n",
       "              -1.2354e+00, -1.0922e+00],\n",
       "             ...,\n",
       "             [-1.2639e+00, -1.1833e+00, -1.1047e+00,  ..., -9.0489e-01,\n",
       "              -9.0747e-01, -1.2372e+00],\n",
       "             [-1.2589e+00, -1.1250e+00, -9.3077e-01,  ..., -1.2661e+00,\n",
       "              -1.2605e+00, -1.2771e+00],\n",
       "             [-1.2530e+00, -1.1690e+00, -8.7582e-01,  ..., -1.2762e+00,\n",
       "              -1.2783e+00, -1.2767e+00]],\n",
       "  \n",
       "            [[-1.2399e+00, -1.1171e+00, -1.0267e+00,  ..., -1.2518e+00,\n",
       "              -1.2318e+00, -1.2695e+00],\n",
       "             [-1.2433e+00, -8.9738e-01, -4.7017e-01,  ..., -1.2700e+00,\n",
       "              -1.2413e+00, -1.1886e+00],\n",
       "             [-1.0386e+00, -6.8049e-01, -9.6467e-01,  ..., -1.2706e+00,\n",
       "              -1.2405e+00, -1.0957e+00],\n",
       "             ...,\n",
       "             [-1.2681e+00, -1.1865e+00, -1.1082e+00,  ..., -9.0489e-01,\n",
       "              -9.0747e-01, -1.2372e+00],\n",
       "             [-1.2639e+00, -1.1282e+00, -9.2997e-01,  ..., -1.2661e+00,\n",
       "              -1.2605e+00, -1.2771e+00],\n",
       "             [-1.2554e+00, -1.1758e+00, -8.7893e-01,  ..., -1.2762e+00,\n",
       "              -1.2783e+00, -1.2767e+00]],\n",
       "  \n",
       "            [[-1.2399e+00, -1.1143e+00, -1.0144e+00,  ..., -1.2518e+00,\n",
       "              -1.2318e+00, -1.2695e+00],\n",
       "             [-1.2506e+00, -9.1579e-01, -4.6080e-01,  ..., -1.2700e+00,\n",
       "              -1.2413e+00, -1.1886e+00],\n",
       "             [-1.0552e+00, -7.4014e-01, -9.5278e-01,  ..., -1.2706e+00,\n",
       "              -1.2405e+00, -1.0957e+00],\n",
       "             ...,\n",
       "             [-1.2630e+00, -1.1837e+00, -1.1065e+00,  ..., -9.0489e-01,\n",
       "              -9.0747e-01, -1.2372e+00],\n",
       "             [-1.2557e+00, -1.1235e+00, -9.2216e-01,  ..., -1.2661e+00,\n",
       "              -1.2605e+00, -1.2771e+00],\n",
       "             [-1.2470e+00, -1.1631e+00, -8.6815e-01,  ..., -1.2762e+00,\n",
       "              -1.2783e+00, -1.2767e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[-5.0734e-01, -5.3746e-01, -5.7365e-01,  ..., -4.1505e-01,\n",
       "              -4.4799e-01, -4.6773e-01],\n",
       "             [-5.1129e-01, -5.3245e-01, -5.7742e-01,  ..., -4.3139e-01,\n",
       "              -4.5214e-01, -4.6678e-01],\n",
       "             [-5.3914e-01, -5.3205e-01, -5.4851e-01,  ..., -4.6330e-01,\n",
       "              -4.4820e-01, -4.4618e-01],\n",
       "             ...,\n",
       "             [ 1.3031e+00,  6.9541e-01, -7.1831e-03,  ..., -4.0156e-01,\n",
       "              -3.1602e-01, -2.8740e-01],\n",
       "             [ 8.9864e-01,  4.8351e-01,  6.9595e-02,  ..., -4.4758e-01,\n",
       "              -3.7546e-01, -2.9447e-01],\n",
       "             [ 7.1980e-01,  5.7612e-01,  1.6040e-01,  ..., -4.3733e-01,\n",
       "              -3.7046e-01, -3.1779e-01]],\n",
       "  \n",
       "            [[-5.0734e-01, -5.3746e-01, -5.7365e-01,  ..., -4.1494e-01,\n",
       "              -4.5003e-01, -4.7693e-01],\n",
       "             [-5.0875e-01, -5.3198e-01, -5.7716e-01,  ..., -4.3070e-01,\n",
       "              -4.5192e-01, -4.7286e-01],\n",
       "             [-5.2868e-01, -5.3024e-01, -5.4703e-01,  ..., -4.6330e-01,\n",
       "              -4.4820e-01, -4.4618e-01],\n",
       "             ...,\n",
       "             [ 1.3031e+00,  6.9541e-01, -7.1831e-03,  ..., -3.9887e-01,\n",
       "              -3.1903e-01, -2.7579e-01],\n",
       "             [ 8.9864e-01,  4.8351e-01,  6.9595e-02,  ..., -4.4283e-01,\n",
       "              -3.6451e-01, -2.8529e-01],\n",
       "             [ 7.1980e-01,  5.7612e-01,  1.6040e-01,  ..., -4.3254e-01,\n",
       "              -3.6350e-01, -3.0918e-01]],\n",
       "  \n",
       "            [[-5.0734e-01, -5.3746e-01, -5.7365e-01,  ..., -4.1505e-01,\n",
       "              -4.4799e-01, -4.6773e-01],\n",
       "             [-5.0875e-01, -5.3198e-01, -5.7716e-01,  ..., -4.3139e-01,\n",
       "              -4.5214e-01, -4.6678e-01],\n",
       "             [-5.2868e-01, -5.3024e-01, -5.4703e-01,  ..., -4.6330e-01,\n",
       "              -4.4820e-01, -4.4618e-01],\n",
       "             ...,\n",
       "             [ 1.2590e+00,  5.3824e-01,  7.6661e-02,  ..., -3.9741e-01,\n",
       "              -3.1902e-01, -2.7620e-01],\n",
       "             [ 8.8673e-01,  3.9361e-01,  1.1202e-01,  ..., -4.4454e-01,\n",
       "              -3.6900e-01, -2.8665e-01],\n",
       "             [ 8.0043e-01,  5.6813e-01,  2.4735e-01,  ..., -4.3333e-01,\n",
       "              -3.6843e-01, -3.1788e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.1458e+00,  1.3896e+00,  1.3298e+00,  ..., -3.2016e-01,\n",
       "              -2.8557e-01, -3.1352e-01],\n",
       "             [ 1.1524e+00,  1.3726e+00,  1.3046e+00,  ..., -2.2449e-01,\n",
       "              -3.1259e-01, -3.3095e-01],\n",
       "             [ 1.2718e+00,  1.4572e+00,  1.3438e+00,  ..., -1.9144e-01,\n",
       "              -2.5577e-01, -3.6069e-01],\n",
       "             ...,\n",
       "             [ 1.1721e+00,  1.1951e+00,  1.2429e+00,  ...,  1.7563e+00,\n",
       "               1.7381e+00,  1.7257e+00],\n",
       "             [ 1.0538e+00,  1.0378e+00,  1.0157e+00,  ...,  1.7460e+00,\n",
       "               1.7487e+00,  1.7496e+00],\n",
       "             [ 9.2931e-01,  9.8175e-01,  1.0019e+00,  ...,  1.7657e+00,\n",
       "               1.7740e+00,  1.7770e+00]],\n",
       "  \n",
       "            [[ 1.1546e+00,  1.3702e+00,  1.2829e+00,  ..., -2.8922e-01,\n",
       "              -3.1674e-01, -2.7839e-01],\n",
       "             [ 1.2103e+00,  1.3878e+00,  1.2829e+00,  ..., -9.7539e-02,\n",
       "              -3.0238e-01, -3.0589e-01],\n",
       "             [ 1.3072e+00,  1.4780e+00,  1.3536e+00,  ..., -1.1597e-01,\n",
       "              -2.2335e-01, -3.2494e-01],\n",
       "             ...,\n",
       "             [ 1.1829e+00,  1.1943e+00,  1.2251e+00,  ...,  1.7460e+00,\n",
       "               1.7356e+00,  1.7466e+00],\n",
       "             [ 1.0505e+00,  1.0371e+00,  1.0197e+00,  ...,  1.7245e+00,\n",
       "               1.7366e+00,  1.7458e+00],\n",
       "             [ 9.4547e-01,  9.5979e-01,  9.6638e-01,  ...,  1.7723e+00,\n",
       "               1.7817e+00,  1.7725e+00]],\n",
       "  \n",
       "            [[ 1.1421e+00,  1.3212e+00,  1.2245e+00,  ..., -2.4834e-01,\n",
       "              -3.1136e-01, -3.0954e-01],\n",
       "             [ 1.2489e+00,  1.4007e+00,  1.2792e+00,  ..., -1.0374e-02,\n",
       "              -2.6324e-01, -2.9424e-01],\n",
       "             [ 1.3287e+00,  1.4922e+00,  1.3629e+00,  ..., -1.0633e-01,\n",
       "              -2.2596e-01, -2.5411e-01],\n",
       "             ...,\n",
       "             [ 1.1672e+00,  1.1963e+00,  1.2240e+00,  ...,  1.7479e+00,\n",
       "               1.7556e+00,  1.7531e+00],\n",
       "             [ 1.0413e+00,  1.0289e+00,  1.0208e+00,  ...,  1.7214e+00,\n",
       "               1.7400e+00,  1.7328e+00],\n",
       "             [ 9.5464e-01,  9.5159e-01,  9.6733e-01,  ...,  1.7414e+00,\n",
       "               1.7729e+00,  1.7667e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1468e+00,\n",
       "               1.1445e+00,  1.1509e+00],\n",
       "             [ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1358e+00,\n",
       "               1.1382e+00,  1.1418e+00],\n",
       "             [ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1204e+00,\n",
       "               1.1270e+00,  1.1310e+00],\n",
       "             ...,\n",
       "             [ 8.0434e-01,  8.0676e-01,  8.1088e-01,  ...,  9.9398e-01,\n",
       "               9.8692e-01,  1.0011e+00],\n",
       "             [ 7.9874e-01,  8.0423e-01,  8.1071e-01,  ...,  9.9257e-01,\n",
       "               9.9270e-01,  9.9835e-01],\n",
       "             [ 8.0677e-01,  8.0516e-01,  8.1232e-01,  ...,  9.9559e-01,\n",
       "               9.9463e-01,  1.0119e+00]],\n",
       "  \n",
       "            [[ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1468e+00,\n",
       "               1.1445e+00,  1.1509e+00],\n",
       "             [ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1358e+00,\n",
       "               1.1382e+00,  1.1420e+00],\n",
       "             [ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1232e+00,\n",
       "               1.1283e+00,  1.1319e+00],\n",
       "             ...,\n",
       "             [ 8.0434e-01,  8.0676e-01,  8.1088e-01,  ...,  9.9398e-01,\n",
       "               9.8692e-01,  1.0011e+00],\n",
       "             [ 7.9874e-01,  8.0423e-01,  8.1071e-01,  ...,  9.9257e-01,\n",
       "               9.9270e-01,  9.9835e-01],\n",
       "             [ 8.0677e-01,  8.0516e-01,  8.1232e-01,  ...,  9.9559e-01,\n",
       "               9.9463e-01,  1.0119e+00]],\n",
       "  \n",
       "            [[ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1557e+00,\n",
       "               1.1671e+00,  1.1656e+00],\n",
       "             [ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1479e+00,\n",
       "               1.1555e+00,  1.1589e+00],\n",
       "             [ 9.2682e-01,  9.2682e-01,  9.2682e-01,  ...,  1.1426e+00,\n",
       "               1.1456e+00,  1.1436e+00],\n",
       "             ...,\n",
       "             [ 8.0388e-01,  8.0477e-01,  8.1104e-01,  ...,  1.0204e+00,\n",
       "               1.0175e+00,  1.0242e+00],\n",
       "             [ 7.9762e-01,  7.9888e-01,  8.0485e-01,  ...,  1.0162e+00,\n",
       "               1.0134e+00,  1.0261e+00],\n",
       "             [ 8.0655e-01,  8.0572e-01,  8.0546e-01,  ...,  1.0193e+00,\n",
       "               1.0303e+00,  1.0337e+00]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 9.7684e-01,  9.7433e-01,  9.8140e-01,  ...,  1.1650e+00,\n",
       "               1.1709e+00,  1.1789e+00],\n",
       "             [ 9.7533e-01,  9.7490e-01,  9.8140e-01,  ...,  1.1519e+00,\n",
       "               1.1675e+00,  1.1764e+00],\n",
       "             [ 9.7007e-01,  9.7433e-01,  9.7711e-01,  ...,  1.1464e+00,\n",
       "               1.1597e+00,  1.1667e+00],\n",
       "             ...,\n",
       "             [-1.1404e+00, -1.1508e+00, -1.1507e+00,  ...,  9.7987e-01,\n",
       "               9.9299e-01,  1.0113e+00],\n",
       "             [-1.1231e+00, -1.1550e+00, -1.1626e+00,  ...,  9.8390e-01,\n",
       "               9.9618e-01,  1.0178e+00],\n",
       "             [-1.1445e+00, -1.1675e+00, -1.1709e+00,  ...,  9.9706e-01,\n",
       "               1.0164e+00,  1.0281e+00]],\n",
       "  \n",
       "            [[ 9.7348e-01,  9.8063e-01,  1.0068e+00,  ...,  1.1650e+00,\n",
       "               1.1715e+00,  1.1813e+00],\n",
       "             [ 9.7429e-01,  9.7534e-01,  9.9924e-01,  ...,  1.1499e+00,\n",
       "               1.1603e+00,  1.1763e+00],\n",
       "             [ 9.6835e-01,  9.7034e-01,  9.8928e-01,  ...,  1.1412e+00,\n",
       "               1.1559e+00,  1.1634e+00],\n",
       "             ...,\n",
       "             [-1.1486e+00, -1.1553e+00, -1.1507e+00,  ...,  9.7987e-01,\n",
       "               9.9299e-01,  1.0113e+00],\n",
       "             [-1.1417e+00, -1.1643e+00, -1.1668e+00,  ...,  9.8390e-01,\n",
       "               9.9618e-01,  1.0178e+00],\n",
       "             [-1.1612e+00, -1.1722e+00, -1.1744e+00,  ...,  9.9706e-01,\n",
       "               1.0164e+00,  1.0281e+00]],\n",
       "  \n",
       "            [[ 9.7556e-01,  9.9699e-01,  1.0115e+00,  ...,  1.1643e+00,\n",
       "               1.1676e+00,  1.1758e+00],\n",
       "             [ 9.8279e-01,  9.9291e-01,  1.0095e+00,  ...,  1.1513e+00,\n",
       "               1.1650e+00,  1.1737e+00],\n",
       "             [ 9.6971e-01,  9.7884e-01,  1.0003e+00,  ...,  1.1445e+00,\n",
       "               1.1588e+00,  1.1686e+00],\n",
       "             ...,\n",
       "             [-1.1571e+00, -1.1532e+00, -1.1463e+00,  ...,  9.8236e-01,\n",
       "               1.0022e+00,  1.0188e+00],\n",
       "             [-1.1616e+00, -1.1627e+00, -1.1609e+00,  ...,  9.8812e-01,\n",
       "               1.0082e+00,  1.0232e+00],\n",
       "             [-1.1684e+00, -1.1715e+00, -1.1732e+00,  ...,  1.0079e+00,\n",
       "               1.0267e+00,  1.0327e+00]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 1.5250e+00,  1.6588e+00,  1.4502e+00,  ...,  2.5789e-01,\n",
       "               2.6714e-01,  2.4388e-01],\n",
       "             [ 1.7507e+00,  1.9249e+00,  1.2005e+00,  ...,  3.8021e-01,\n",
       "               4.3615e-01,  3.5919e-01],\n",
       "             [ 1.2792e+00,  1.3961e+00,  1.4540e+00,  ...,  3.3912e-01,\n",
       "               2.2939e-01,  1.4842e-01],\n",
       "             ...,\n",
       "             [-3.9068e-01,  1.7696e-01,  6.1748e-02,  ...,  5.3509e-01,\n",
       "               6.4965e-01,  7.3271e-01],\n",
       "             [-4.3262e-01,  1.4004e-01,  9.0760e-02,  ...,  6.8177e-01,\n",
       "               5.5024e-01,  3.3961e-01],\n",
       "             [-8.2056e-02,  1.4914e-01, -6.7174e-02,  ...,  6.0786e-01,\n",
       "               6.4120e-01,  5.5795e-01]],\n",
       "  \n",
       "            [[ 1.5165e+00,  1.6467e+00,  1.5063e+00,  ...,  3.1716e-01,\n",
       "               2.5099e-01,  2.4881e-01],\n",
       "             [ 1.7101e+00,  1.9329e+00,  1.3492e+00,  ...,  3.5551e-01,\n",
       "               3.9833e-01,  3.7219e-01],\n",
       "             [ 1.3576e+00,  1.4345e+00,  1.5911e+00,  ...,  3.9901e-01,\n",
       "               2.3450e-01,  1.7322e-01],\n",
       "             ...,\n",
       "             [-3.1975e-01,  1.9748e-01,  4.9391e-02,  ...,  5.3162e-01,\n",
       "               6.3790e-01,  7.5595e-01],\n",
       "             [-3.7187e-01,  1.7241e-01,  8.6657e-02,  ...,  6.7786e-01,\n",
       "               5.7890e-01,  3.4882e-01],\n",
       "             [-4.2228e-02,  1.4996e-01, -7.6738e-02,  ...,  6.1569e-01,\n",
       "               6.4712e-01,  5.8979e-01]],\n",
       "  \n",
       "            [[ 1.4976e+00,  1.5689e+00,  1.5329e+00,  ...,  3.9467e-01,\n",
       "               2.8121e-01,  2.8835e-01],\n",
       "             [ 1.6663e+00,  1.8950e+00,  1.5214e+00,  ...,  3.4893e-01,\n",
       "               3.7612e-01,  4.0241e-01],\n",
       "             [ 1.4447e+00,  1.4346e+00,  1.6604e+00,  ...,  5.0716e-01,\n",
       "               2.6140e-01,  1.9715e-01],\n",
       "             ...,\n",
       "             [-2.5752e-01,  2.0650e-01,  3.1809e-02,  ...,  5.1257e-01,\n",
       "               6.1411e-01,  7.4601e-01],\n",
       "             [-2.9830e-01,  1.7495e-01,  5.7287e-02,  ...,  6.5732e-01,\n",
       "               6.0107e-01,  3.4577e-01],\n",
       "             [ 2.8114e-02,  1.3539e-01, -8.5390e-02,  ...,  6.0284e-01,\n",
       "               6.4260e-01,  6.2079e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-7.5411e-01, -5.3624e-01, -3.5916e-01,  ...,  1.3645e+00,\n",
       "               1.2625e+00,  1.3991e+00],\n",
       "             [-8.1053e-01, -4.4194e-01, -2.0499e-01,  ...,  1.1188e+00,\n",
       "               1.2537e+00,  1.3720e+00],\n",
       "             [-8.5111e-01, -8.9748e-01, -7.4877e-01,  ...,  1.1025e+00,\n",
       "               1.3128e+00,  1.3188e+00],\n",
       "             ...,\n",
       "             [-5.9377e-01, -7.0394e-01, -1.9141e-01,  ...,  5.3932e-01,\n",
       "               4.3672e-01,  2.1955e-01],\n",
       "             [-8.0342e-01, -5.5795e-01, -3.7252e-01,  ...,  3.5318e-01,\n",
       "               4.7591e-01,  1.9964e-01],\n",
       "             [-8.6547e-01, -5.5516e-01, -6.1152e-01,  ...,  4.9152e-02,\n",
       "               1.1118e-01,  1.8934e-01]],\n",
       "  \n",
       "            [[-7.9035e-01, -5.2165e-01, -4.4784e-01,  ...,  1.4120e+00,\n",
       "               1.1911e+00,  1.4371e+00],\n",
       "             [-8.2279e-01, -6.3129e-01, -4.2618e-01,  ...,  1.3139e+00,\n",
       "               1.0497e+00,  1.5354e+00],\n",
       "             [-7.0349e-01, -8.7944e-01, -8.3721e-01,  ...,  1.2297e+00,\n",
       "               1.2082e+00,  1.4318e+00],\n",
       "             ...,\n",
       "             [-6.8313e-01, -6.4565e-01, -1.8985e-01,  ...,  5.3790e-01,\n",
       "               5.1324e-01,  2.6603e-01],\n",
       "             [-8.2848e-01, -4.6929e-01, -3.6745e-01,  ...,  2.9301e-01,\n",
       "               4.9526e-01,  2.8138e-01],\n",
       "             [-8.4372e-01, -4.9056e-01, -5.9602e-01,  ...,  7.2744e-02,\n",
       "               1.0704e-01,  1.8630e-01]],\n",
       "  \n",
       "            [[-5.6565e-01, -6.8354e-01, -4.5474e-01,  ...,  1.4701e+00,\n",
       "               1.2298e+00,  1.2520e+00],\n",
       "             [-6.9316e-01, -8.0605e-01, -6.3471e-01,  ...,  1.4387e+00,\n",
       "               1.0180e+00,  1.3776e+00],\n",
       "             [-4.2064e-01, -8.4465e-01, -8.4997e-01,  ...,  1.3281e+00,\n",
       "               1.1299e+00,  1.3591e+00],\n",
       "             ...,\n",
       "             [-7.6894e-01, -5.5028e-01, -1.7997e-01,  ...,  5.1317e-01,\n",
       "               5.4692e-01,  2.9756e-01],\n",
       "             [-8.3163e-01, -3.8653e-01, -3.6626e-01,  ...,  2.2612e-01,\n",
       "               4.7908e-01,  3.3984e-01],\n",
       "             [-7.7731e-01, -4.1898e-01, -5.8785e-01,  ...,  1.0955e-01,\n",
       "               7.1219e-02,  1.5077e-01]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "          [[[[ 1.7860e-01,  1.4940e-01,  1.6925e-01,  ..., -9.6795e-02,\n",
       "              -1.8698e-01, -2.6021e-01],\n",
       "             [ 1.7203e-01,  2.0038e-01,  1.7527e-01,  ..., -5.1987e-02,\n",
       "              -1.9031e-01, -2.6364e-01],\n",
       "             [ 1.8351e-01,  2.1327e-01,  1.9621e-01,  ..., -2.0028e-02,\n",
       "              -1.0828e-01, -2.2505e-01],\n",
       "             ...,\n",
       "             [ 1.5249e+00,  1.5249e+00,  1.5182e+00,  ..., -5.3928e-01,\n",
       "              -4.2398e-01,  3.5793e-02],\n",
       "             [ 1.5124e+00,  1.5125e+00,  1.5120e+00,  ..., -4.3217e-01,\n",
       "              -3.0889e-01, -9.9973e-03],\n",
       "             [ 1.5103e+00,  1.5108e+00,  1.5191e+00,  ...,  7.0065e-02,\n",
       "               2.1737e-01, -1.2263e-01]],\n",
       "  \n",
       "            [[ 5.4709e-01,  4.9764e-01,  5.7465e-01,  ..., -9.8284e-02,\n",
       "              -1.7154e-01, -2.1517e-01],\n",
       "             [ 1.9642e-01,  1.6786e-01,  1.7801e-01,  ..., -1.0389e-01,\n",
       "              -1.8869e-01, -2.5874e-01],\n",
       "             [ 1.5627e-01,  1.9933e-01,  1.7247e-01,  ..., -3.1555e-02,\n",
       "              -1.8737e-01, -2.6364e-01],\n",
       "             ...,\n",
       "             [ 1.5202e+00,  1.5120e+00,  1.5203e+00,  ..., -5.4136e-01,\n",
       "              -4.6681e-01, -1.4177e-01],\n",
       "             [ 1.5117e+00,  1.5106e+00,  1.5117e+00,  ..., -5.5051e-01,\n",
       "              -4.2657e-01,  1.0882e-01],\n",
       "             [ 1.5103e+00,  1.5103e+00,  1.5096e+00,  ..., -4.6773e-01,\n",
       "              -2.9901e-01,  2.0497e-01]],\n",
       "  \n",
       "            [[ 1.0115e+00,  9.5777e-01,  9.9221e-01,  ...,  1.6200e-02,\n",
       "              -6.8123e-02,  7.7914e-02],\n",
       "             [ 4.9388e-01,  4.4103e-01,  5.3380e-01,  ..., -1.2128e-01,\n",
       "              -1.7534e-01, -2.2107e-01],\n",
       "             [ 1.6310e-01,  1.5500e-01,  1.5411e-01,  ..., -1.0522e-01,\n",
       "              -1.9159e-01, -2.7527e-01],\n",
       "             ...,\n",
       "             [ 1.5212e+00,  1.5108e+00,  1.5155e+00,  ..., -5.4926e-01,\n",
       "              -5.0870e-01, -3.2960e-01],\n",
       "             [ 1.5184e+00,  1.5109e+00,  1.5167e+00,  ..., -5.8240e-01,\n",
       "              -4.7363e-01, -1.8544e-01],\n",
       "             [ 1.5107e+00,  1.5116e+00,  1.5134e+00,  ..., -6.3833e-01,\n",
       "              -4.4116e-01,  1.9884e-01]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[ 1.2249e+00,  1.2457e+00,  1.2549e+00,  ...,  7.4908e-01,\n",
       "               8.2475e-02,  1.5797e-01],\n",
       "             [ 1.2616e+00,  1.2657e+00,  1.2202e+00,  ...,  7.3870e-01,\n",
       "               3.8649e-01,  4.0784e-01],\n",
       "             [ 1.2641e+00,  1.2473e+00,  1.2065e+00,  ...,  9.3742e-01,\n",
       "               8.1848e-01,  8.6708e-01],\n",
       "             ...,\n",
       "             [ 1.2087e+00,  1.2570e+00,  1.2833e+00,  ..., -4.5867e-01,\n",
       "              -6.6055e-01, -6.6977e-01],\n",
       "             [ 1.2111e+00,  1.2532e+00,  1.2749e+00,  ..., -4.9437e-01,\n",
       "              -6.5394e-01, -6.9945e-01],\n",
       "             [ 1.2592e+00,  1.2753e+00,  1.2659e+00,  ..., -4.1744e-01,\n",
       "              -6.4737e-01, -7.2815e-01]],\n",
       "  \n",
       "            [[ 1.2249e+00,  1.2457e+00,  1.2549e+00,  ...,  7.4908e-01,\n",
       "               8.2475e-02,  1.5797e-01],\n",
       "             [ 1.2616e+00,  1.2657e+00,  1.2202e+00,  ...,  7.3949e-01,\n",
       "               3.8662e-01,  4.0740e-01],\n",
       "             [ 1.2641e+00,  1.2473e+00,  1.2065e+00,  ...,  9.4133e-01,\n",
       "               8.1659e-01,  8.6103e-01],\n",
       "             ...,\n",
       "             [ 1.2094e+00,  1.2589e+00,  1.2828e+00,  ..., -4.8723e-01,\n",
       "              -7.0091e-01, -6.9919e-01],\n",
       "             [ 1.2114e+00,  1.2538e+00,  1.2752e+00,  ..., -5.7718e-01,\n",
       "              -7.2689e-01, -7.4068e-01],\n",
       "             [ 1.2592e+00,  1.2752e+00,  1.2695e+00,  ..., -3.9453e-01,\n",
       "              -7.6217e-01, -7.6791e-01]],\n",
       "  \n",
       "            [[ 1.2249e+00,  1.2457e+00,  1.2549e+00,  ...,  7.4908e-01,\n",
       "               8.2475e-02,  1.5797e-01],\n",
       "             [ 1.2616e+00,  1.2657e+00,  1.2202e+00,  ...,  7.3949e-01,\n",
       "               3.8662e-01,  4.0740e-01],\n",
       "             [ 1.2641e+00,  1.2473e+00,  1.2065e+00,  ...,  9.4133e-01,\n",
       "               8.1659e-01,  8.6103e-01],\n",
       "             ...,\n",
       "             [ 1.2094e+00,  1.2589e+00,  1.2828e+00,  ..., -4.8964e-01,\n",
       "              -7.0643e-01, -7.0001e-01],\n",
       "             [ 1.2114e+00,  1.2538e+00,  1.2752e+00,  ..., -5.8299e-01,\n",
       "              -7.2987e-01, -7.4077e-01],\n",
       "             [ 1.2592e+00,  1.2752e+00,  1.2695e+00,  ..., -3.8716e-01,\n",
       "              -7.6621e-01, -7.6791e-01]]]]]),\n",
       "  'responses': tensor([[[6.2725e-08, 1.5484e-08, 8.6449e-09,  ..., 6.4939e-09,\n",
       "            1.9378e-08, 1.3059e-08],\n",
       "           [5.6876e-02, 2.1745e-07, 4.2500e-09,  ..., 7.1709e-09,\n",
       "            1.5093e-07, 1.3812e-08],\n",
       "           [1.3601e-07, 2.1302e+00, 2.9259e-09,  ..., 1.1829e+00,\n",
       "            1.6280e-01, 2.3847e-08],\n",
       "           ...,\n",
       "           [3.9993e-07, 1.7355e-08, 7.1607e-09,  ..., 3.7941e-09,\n",
       "            1.1166e-08, 8.5400e-08],\n",
       "           [7.5033e-01, 7.4884e-02, 1.1914e-08,  ..., 3.2651e-09,\n",
       "            5.3026e-09, 4.8186e-08],\n",
       "           [6.6764e-08, 2.7064e-07, 4.6936e-01,  ..., 3.1239e-09,\n",
       "            3.6501e-09, 1.8141e-08]],\n",
       "  \n",
       "          [[3.7631e-08, 2.7802e-01, 5.6674e-09,  ..., 7.0721e-01,\n",
       "            6.2580e-10, 1.7016e-09],\n",
       "           [1.3292e-07, 7.2055e-08, 1.1955e-08,  ..., 1.4574e-08,\n",
       "            5.3072e-10, 1.8141e-09],\n",
       "           [2.2637e-07, 2.1218e-07, 1.4143e-08,  ..., 2.2836e-09,\n",
       "            4.9449e-10, 2.2268e-09],\n",
       "           ...,\n",
       "           [1.5687e-07, 1.5437e-08, 4.9097e-09,  ..., 7.9802e-11,\n",
       "            2.9548e-09, 1.4906e-09],\n",
       "           [9.5847e-08, 6.0000e-08, 3.1491e-09,  ..., 7.9037e-11,\n",
       "            4.6814e-09, 1.6034e-09],\n",
       "           [1.0769e-07, 2.4570e-08, 2.4332e-09,  ..., 7.5984e-11,\n",
       "            5.3183e-09, 1.7668e-09]],\n",
       "  \n",
       "          [[2.2328e+00, 2.2209e-09, 2.3030e-08,  ..., 5.6443e-02,\n",
       "            2.3045e-08, 5.7043e-09],\n",
       "           [1.1228e-07, 1.8203e-09, 1.1619e-01,  ..., 1.2516e+00,\n",
       "            1.1840e-08, 5.7964e-09],\n",
       "           [3.7104e-08, 1.7494e-09, 1.4148e-08,  ..., 4.7185e-09,\n",
       "            2.5823e-01, 5.4098e-09],\n",
       "           ...,\n",
       "           [1.6315e-09, 2.6216e-10, 7.6420e-10,  ..., 1.2303e-08,\n",
       "            1.6934e-09, 3.7598e-09],\n",
       "           [1.3481e-09, 2.1278e-10, 8.7454e-10,  ..., 7.1726e-09,\n",
       "            1.4285e-09, 2.7347e-09],\n",
       "           [1.1970e-09, 1.6851e-10, 8.6309e-10,  ..., 3.4910e-09,\n",
       "            1.3929e-09, 2.2291e-09]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[8.4528e-08, 1.2516e-08, 4.0996e-09,  ..., 4.2611e-01,\n",
       "            7.8195e-02, 2.2905e-08],\n",
       "           [1.1000e-07, 6.5164e-09, 2.2774e-08,  ..., 4.5354e-09,\n",
       "            1.6446e+00, 6.2882e-08],\n",
       "           [1.0218e-07, 7.6450e-09, 4.8905e+00,  ..., 5.2123e-09,\n",
       "            1.2373e-08, 4.3202e-08],\n",
       "           ...,\n",
       "           [1.3840e-07, 8.4556e-09, 2.1838e-08,  ..., 3.8740e-10,\n",
       "            3.4386e+00, 6.2241e-08],\n",
       "           [2.0868e-07, 2.0878e-08, 1.4515e-08,  ..., 4.5942e-10,\n",
       "            1.7559e-08, 2.2576e+00],\n",
       "           [1.7812e-06, 1.3795e-08, 7.9537e-09,  ..., 5.0848e-10,\n",
       "            1.4517e-08, 9.5105e-08]],\n",
       "  \n",
       "          [[2.0204e-08, 1.0467e-09, 3.8549e-10,  ..., 3.4212e-08,\n",
       "            6.5874e-10, 1.7233e-10],\n",
       "           [2.3917e-08, 1.1966e-09, 4.3007e-10,  ..., 1.9015e-09,\n",
       "            5.4325e-10, 1.6526e-10],\n",
       "           [2.3842e-08, 1.1239e-09, 4.7221e-10,  ..., 2.2104e-09,\n",
       "            5.1024e-10, 1.8572e-10],\n",
       "           ...,\n",
       "           [1.0107e-08, 9.8994e-10, 2.0463e-10,  ..., 4.5301e-09,\n",
       "            6.4052e-09, 8.6477e-10],\n",
       "           [1.1127e-08, 9.5314e-10, 2.4484e-10,  ..., 4.5229e-01,\n",
       "            8.3970e-09, 1.1044e-09],\n",
       "           [1.2327e-08, 9.3969e-10, 3.1494e-10,  ..., 8.0265e-09,\n",
       "            8.5307e-09, 1.3163e-09]],\n",
       "  \n",
       "          [[1.0287e+00, 1.5075e-08, 1.4224e-08,  ..., 7.1451e-09,\n",
       "            1.8852e-08, 1.0094e+00],\n",
       "           [4.2108e-07, 2.5602e-08, 2.1620e-08,  ..., 3.8349e-09,\n",
       "            2.2189e-08, 2.5005e-01],\n",
       "           [1.4257e+00, 4.5474e-08, 1.1686e-08,  ..., 3.0073e-09,\n",
       "            4.2159e-01, 4.1244e-08],\n",
       "           ...,\n",
       "           [2.7018e-07, 1.0060e-08, 3.7548e-09,  ..., 7.7228e-08,\n",
       "            1.5510e-08, 4.7151e-08],\n",
       "           [1.4933e+00, 1.4357e-08, 6.2154e-09,  ..., 1.9153e-08,\n",
       "            1.7982e-08, 3.4917e-08],\n",
       "           [3.0220e-07, 1.9235e-08, 8.6368e-09,  ..., 1.0637e-08,\n",
       "            1.2582e-08, 2.3988e-08]]]),\n",
       "  'eye_tracker': tensor([[[-5.0442e-01, -6.4217e-01, -4.2285e-01,  4.7031e-01],\n",
       "           [-5.3555e-01, -7.3271e-01, -5.8629e-01,  6.5366e-01],\n",
       "           [-4.5981e-01, -7.7081e-01, -8.4708e-01,  7.8052e-01],\n",
       "           ...,\n",
       "           [-5.9587e-01, -1.2104e-01, -5.7694e-01,  4.9256e-01],\n",
       "           [-5.4270e-01, -1.7758e-01, -3.2275e-01,  5.4779e-01],\n",
       "           [-6.3828e-01, -2.3294e-01, -6.9012e-01,  7.1970e-01]],\n",
       "  \n",
       "          [[ 5.2285e-01, -1.2340e+00,  1.4624e+00, -1.4547e+00],\n",
       "           [ 3.7507e-01, -1.1299e+00,  1.3774e+00, -1.5391e+00],\n",
       "           [ 3.7507e-01, -1.1299e+00,  1.3774e+00, -1.5391e+00],\n",
       "           ...,\n",
       "           [ 8.8018e-01,  9.1304e-01,  6.6288e-01, -1.3466e+00],\n",
       "           [ 8.3566e-01,  8.4805e-01,  5.3686e-01, -9.2197e-01],\n",
       "           [ 8.3566e-01,  8.4805e-01,  5.3686e-01, -9.2197e-01]],\n",
       "  \n",
       "          [[-4.7219e-01,  8.9121e-03, -8.1933e-01,  1.0301e+00],\n",
       "           [-4.7219e-01,  8.9121e-03, -8.1933e-01,  1.0301e+00],\n",
       "           [-4.6292e-01, -1.5879e-01, -2.3116e-01,  8.2248e-01],\n",
       "           ...,\n",
       "           [-9.1855e-01,  1.6924e-01, -1.1227e+00,  1.8830e+00],\n",
       "           [-9.1855e-01,  1.6924e-01, -1.1227e+00,  1.8830e+00],\n",
       "           [-9.9968e-01,  1.2588e-01, -2.6925e-01,  1.1452e+00]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 7.2640e-01, -4.4263e-01,  3.3593e-02, -1.4759e+00],\n",
       "           [ 7.2640e-01, -4.4263e-01,  3.3593e-02, -1.4759e+00],\n",
       "           [ 6.9844e-01, -7.6091e-01,  1.4396e-01, -1.8599e+00],\n",
       "           ...,\n",
       "           [ 3.6038e-01,  5.7553e-01,  4.8930e-01, -9.8894e-01],\n",
       "           [ 3.6038e-01,  5.7553e-01,  4.8930e-01, -9.8894e-01],\n",
       "           [ 1.2174e-01,  4.8313e-01, -1.8384e-02, -6.4101e-01]],\n",
       "  \n",
       "          [[ 3.3995e-01, -1.8624e-03, -1.0731e+00, -1.4270e-01],\n",
       "           [ 2.3860e-01, -1.0630e-01, -9.7986e-01, -1.6171e-01],\n",
       "           [ 2.3860e-01, -1.0630e-01, -9.7986e-01, -1.6171e-01],\n",
       "           ...,\n",
       "           [ 5.0056e-01, -2.8234e-01, -7.3445e-01, -1.3412e-01],\n",
       "           [ 4.7581e-01, -3.3649e-01, -7.3661e-01,  1.3299e-02],\n",
       "           [ 4.7581e-01, -3.3649e-01, -7.3661e-01,  1.3299e-02]],\n",
       "  \n",
       "          [[ 2.3621e-01, -3.0218e-01,  1.1657e+00,  3.8464e-01],\n",
       "           [ 2.3621e-01, -3.0218e-01,  1.1657e+00,  3.8464e-01],\n",
       "           [ 2.0542e-01, -2.8775e-01,  1.1233e+00,  4.1416e-01],\n",
       "           ...,\n",
       "           [ 4.7191e-02, -3.1749e-01,  1.1668e+00,  9.4242e-02],\n",
       "           [ 4.7191e-02, -3.1749e-01,  1.1668e+00,  9.4242e-02],\n",
       "           [ 1.5213e-02, -3.1896e-01,  1.1858e+00,  1.6712e-01]]]),\n",
       "  'treadmill': tensor([[[0.2315],\n",
       "           [0.2315],\n",
       "           [0.2315],\n",
       "           ...,\n",
       "           [0.2638],\n",
       "           [0.2695],\n",
       "           [0.2751]],\n",
       "  \n",
       "          [[0.2165],\n",
       "           [0.2165],\n",
       "           [0.2192],\n",
       "           ...,\n",
       "           [0.2315],\n",
       "           [0.2315],\n",
       "           [0.2315]],\n",
       "  \n",
       "          [[0.2315],\n",
       "           [0.2315],\n",
       "           [0.2315],\n",
       "           ...,\n",
       "           [0.2315],\n",
       "           [0.2315],\n",
       "           [0.2315]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.2368],\n",
       "           [0.3144],\n",
       "           [0.3013],\n",
       "           ...,\n",
       "           [0.2266],\n",
       "           [0.2311],\n",
       "           [0.2315]],\n",
       "  \n",
       "          [[0.2315],\n",
       "           [0.2315],\n",
       "           [0.2315],\n",
       "           ...,\n",
       "           [0.2315],\n",
       "           [0.2315],\n",
       "           [0.2315]],\n",
       "  \n",
       "          [[0.2285],\n",
       "           [0.2315],\n",
       "           [0.2315],\n",
       "           ...,\n",
       "           [0.2165],\n",
       "           [0.2196],\n",
       "           [0.2239]]])})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainer.masking_mode in [\"combined\", \"all\"]:\n",
    "    masking_mode = random.sample(trainer.masking_schemes, 1)[0]\n",
    "    if masking_mode == 'temporal':\n",
    "        trainer.model.encoder.masker.ratio = 0.3\n",
    "    elif masking_mode == 'causal':\n",
    "        trainer.model.encoder.masker.ratio = 0.6\n",
    "    else:\n",
    "        trainer.model.encoder.masker.ratio = trainer.masking_ratio\n",
    "else:\n",
    "    masking_mode = trainer.masking_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neuron'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masking_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef _forward_model_outputs_experanto(self, batch, masking_mode):\\n        B, T, S = batch[1]['responses'].shape\\n        return self.model(\\n            batch[1]['responses'].to(torch.float32).to(self.accelerator.device), \\n            time_attn_mask=torch.ones(B, T).to(torch.int64).to(self.accelerator.device),\\n            space_attn_mask=torch.ones(B, S).to(torch.int64).to(self.accelerator.device),\\n            spikes_timestamps=torch.arange(T).to(torch.int64).repeat(B,1).to(self.accelerator.device),\\n            spikes_spacestamps=torch.arange(S).to(torch.int64).repeat(B,1).to(self.accelerator.device),\\n            targets = float('nan')*torch.ones(B,1).to(torch.int64),\\n            neuron_regions=[['V1']*B]*S,\\n            masking_mode=masking_mode,\\n            spike_augmentation=self.config.data.spike_augmentation,\\n            num_neuron=S,\\n            eid='test-test-test'  # each batch consists of data from the same eid\\n        ) \\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def _forward_model_outputs_experanto(self, batch, masking_mode):\n",
    "        B, T, S = batch[1]['responses'].shape\n",
    "        return self.model(\n",
    "            batch[1]['responses'].to(torch.float32).to(self.accelerator.device), \n",
    "            time_attn_mask=torch.ones(B, T).to(torch.int64).to(self.accelerator.device),\n",
    "            space_attn_mask=torch.ones(B, S).to(torch.int64).to(self.accelerator.device),\n",
    "            spikes_timestamps=torch.arange(T).to(torch.int64).repeat(B,1).to(self.accelerator.device),\n",
    "            spikes_spacestamps=torch.arange(S).to(torch.int64).repeat(B,1).to(self.accelerator.device),\n",
    "            targets = float('nan')*torch.ones(B,1).to(torch.int64),\n",
    "            neuron_regions=[['V1']*B]*S,\n",
    "            masking_mode=masking_mode,\n",
    "            spike_augmentation=self.config.data.spike_augmentation,\n",
    "            num_neuron=S,\n",
    "            eid='test-test-test'  # each batch consists of data from the same eid\n",
    "        ) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.accelerator.device, trainer.config.data.spike_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, S = batch[1]['responses'].shape\n",
    "\n",
    "spikes = batch[1]['responses'].to(torch.float32).to(trainer.accelerator.device) \n",
    "time_attn_mask=torch.ones(B, T).to(torch.int64).to(trainer.accelerator.device)\n",
    "space_attn_mask=torch.ones(B, S).to(torch.int64).to(trainer.accelerator.device)\n",
    "spikes_timestamps=torch.arange(T).to(torch.int64).repeat(B,1).to(trainer.accelerator.device)\n",
    "spikes_spacestamps=torch.arange(S).to(torch.int64).repeat(B,1).to(trainer.accelerator.device)\n",
    "targets = float('nan')*torch.ones(B,1).to(torch.int64)\n",
    "neuron_regions=[['V1']*B]*S\n",
    "masking_mode=masking_mode\n",
    "spike_augmentation=trainer.config.data.spike_augmentation\n",
    "num_neuron=S\n",
    "eid='test-test-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, _T, N = spikes.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = self._forward_model_outputs(batch, masking_mode)\n",
    "# outputs = trainer._forward_model_outputs_experanto(batch, masking_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes, targets_mask = model.encoder.masker(spikes, neuron_regions)\n",
    "# targets_mask = targets_mask.to(torch.int64) & spikes_mask.unsqueeze(-1).expand(B,_T,N).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V1'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(neuron_regions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 16, 7908]), 7908, {'V1'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes.shape, len(neuron_regions), set(neuron_regions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.2725e-08, 1.5484e-08, 8.6449e-09,  ..., 6.4939e-09,\n",
       "          1.9378e-08, 1.3059e-08],\n",
       "         [5.6876e-02, 2.1745e-07, 4.2500e-09,  ..., 7.1709e-09,\n",
       "          1.5093e-07, 1.3812e-08],\n",
       "         [1.3601e-07, 2.1302e+00, 2.9259e-09,  ..., 1.1829e+00,\n",
       "          1.6280e-01, 2.3847e-08],\n",
       "         ...,\n",
       "         [3.9993e-07, 1.7355e-08, 7.1607e-09,  ..., 3.7941e-09,\n",
       "          1.1166e-08, 8.5400e-08],\n",
       "         [7.5033e-01, 7.4884e-02, 1.1914e-08,  ..., 3.2651e-09,\n",
       "          5.3026e-09, 4.8186e-08],\n",
       "         [6.6764e-08, 2.7064e-07, 4.6936e-01,  ..., 3.1239e-09,\n",
       "          3.6501e-09, 1.8141e-08]],\n",
       "\n",
       "        [[3.7631e-08, 2.7802e-01, 5.6674e-09,  ..., 7.0721e-01,\n",
       "          6.2580e-10, 1.7016e-09],\n",
       "         [1.3292e-07, 7.2055e-08, 1.1955e-08,  ..., 1.4574e-08,\n",
       "          5.3072e-10, 1.8141e-09],\n",
       "         [2.2637e-07, 2.1218e-07, 1.4143e-08,  ..., 2.2836e-09,\n",
       "          4.9449e-10, 2.2268e-09],\n",
       "         ...,\n",
       "         [1.5687e-07, 1.5437e-08, 4.9097e-09,  ..., 7.9802e-11,\n",
       "          2.9548e-09, 1.4906e-09],\n",
       "         [9.5847e-08, 6.0000e-08, 3.1491e-09,  ..., 7.9037e-11,\n",
       "          4.6814e-09, 1.6034e-09],\n",
       "         [1.0769e-07, 2.4570e-08, 2.4332e-09,  ..., 7.5984e-11,\n",
       "          5.3183e-09, 1.7668e-09]],\n",
       "\n",
       "        [[2.2328e+00, 2.2209e-09, 2.3030e-08,  ..., 5.6443e-02,\n",
       "          2.3045e-08, 5.7043e-09],\n",
       "         [1.1228e-07, 1.8203e-09, 1.1619e-01,  ..., 1.2516e+00,\n",
       "          1.1840e-08, 5.7964e-09],\n",
       "         [3.7104e-08, 1.7494e-09, 1.4148e-08,  ..., 4.7185e-09,\n",
       "          2.5823e-01, 5.4098e-09],\n",
       "         ...,\n",
       "         [1.6315e-09, 2.6216e-10, 7.6420e-10,  ..., 1.2303e-08,\n",
       "          1.6934e-09, 3.7598e-09],\n",
       "         [1.3481e-09, 2.1278e-10, 8.7454e-10,  ..., 7.1726e-09,\n",
       "          1.4285e-09, 2.7347e-09],\n",
       "         [1.1970e-09, 1.6851e-10, 8.6309e-10,  ..., 3.4910e-09,\n",
       "          1.3929e-09, 2.2291e-09]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[8.4528e-08, 1.2516e-08, 4.0996e-09,  ..., 4.2611e-01,\n",
       "          7.8195e-02, 2.2905e-08],\n",
       "         [1.1000e-07, 6.5164e-09, 2.2774e-08,  ..., 4.5354e-09,\n",
       "          1.6446e+00, 6.2882e-08],\n",
       "         [1.0218e-07, 7.6450e-09, 4.8905e+00,  ..., 5.2123e-09,\n",
       "          1.2373e-08, 4.3202e-08],\n",
       "         ...,\n",
       "         [1.3840e-07, 8.4556e-09, 2.1838e-08,  ..., 3.8740e-10,\n",
       "          3.4386e+00, 6.2241e-08],\n",
       "         [2.0868e-07, 2.0878e-08, 1.4515e-08,  ..., 4.5942e-10,\n",
       "          1.7559e-08, 2.2576e+00],\n",
       "         [1.7812e-06, 1.3795e-08, 7.9537e-09,  ..., 5.0848e-10,\n",
       "          1.4517e-08, 9.5105e-08]],\n",
       "\n",
       "        [[2.0204e-08, 1.0467e-09, 3.8549e-10,  ..., 3.4212e-08,\n",
       "          6.5874e-10, 1.7233e-10],\n",
       "         [2.3917e-08, 1.1966e-09, 4.3007e-10,  ..., 1.9015e-09,\n",
       "          5.4325e-10, 1.6526e-10],\n",
       "         [2.3842e-08, 1.1239e-09, 4.7221e-10,  ..., 2.2104e-09,\n",
       "          5.1024e-10, 1.8572e-10],\n",
       "         ...,\n",
       "         [1.0107e-08, 9.8994e-10, 2.0463e-10,  ..., 4.5301e-09,\n",
       "          6.4052e-09, 8.6477e-10],\n",
       "         [1.1127e-08, 9.5314e-10, 2.4484e-10,  ..., 4.5229e-01,\n",
       "          8.3970e-09, 1.1044e-09],\n",
       "         [1.2327e-08, 9.3969e-10, 3.1494e-10,  ..., 8.0265e-09,\n",
       "          8.5307e-09, 1.3163e-09]],\n",
       "\n",
       "        [[1.0287e+00, 1.5075e-08, 1.4224e-08,  ..., 7.1451e-09,\n",
       "          1.8852e-08, 1.0094e+00],\n",
       "         [4.2108e-07, 2.5602e-08, 2.1620e-08,  ..., 3.8349e-09,\n",
       "          2.2189e-08, 2.5005e-01],\n",
       "         [1.4257e+00, 4.5474e-08, 1.1686e-08,  ..., 3.0073e-09,\n",
       "          4.2159e-01, 4.1244e-08],\n",
       "         ...,\n",
       "         [2.7018e-07, 1.0060e-08, 3.7548e-09,  ..., 7.7228e-08,\n",
       "          1.5510e-08, 4.7151e-08],\n",
       "         [1.4933e+00, 1.4357e-08, 6.2154e-09,  ..., 1.9153e-08,\n",
       "          1.7982e-08, 3.4917e-08],\n",
       "         [3.0220e-07, 1.9235e-08, 8.6368e-09,  ..., 1.0637e-08,\n",
       "          1.2582e-08, 2.3988e-08]]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes, targets_mask = model.encoder.masker(spikes, neuron_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 7908])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes.shape # same as before - [64, 16, 7908]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.2725e-08, 0.0000e+00, 8.6449e-09,  ..., 6.4939e-09,\n",
       "          1.9378e-08, 1.3059e-08],\n",
       "         [5.6876e-02, 0.0000e+00, 4.2500e-09,  ..., 7.1709e-09,\n",
       "          1.5093e-07, 1.3812e-08],\n",
       "         [1.3601e-07, 0.0000e+00, 2.9259e-09,  ..., 1.1829e+00,\n",
       "          1.6280e-01, 2.3847e-08],\n",
       "         ...,\n",
       "         [3.9993e-07, 0.0000e+00, 7.1607e-09,  ..., 3.7941e-09,\n",
       "          1.1166e-08, 8.5400e-08],\n",
       "         [7.5033e-01, 0.0000e+00, 1.1914e-08,  ..., 3.2651e-09,\n",
       "          5.3026e-09, 4.8186e-08],\n",
       "         [6.6764e-08, 0.0000e+00, 4.6936e-01,  ..., 3.1239e-09,\n",
       "          3.6501e-09, 1.8141e-08]],\n",
       "\n",
       "        [[3.7631e-08, 2.7802e-01, 5.6674e-09,  ..., 0.0000e+00,\n",
       "          6.2580e-10, 1.7016e-09],\n",
       "         [1.3292e-07, 7.2055e-08, 1.1955e-08,  ..., 0.0000e+00,\n",
       "          5.3072e-10, 1.8141e-09],\n",
       "         [2.2637e-07, 2.1218e-07, 1.4143e-08,  ..., 0.0000e+00,\n",
       "          4.9449e-10, 2.2268e-09],\n",
       "         ...,\n",
       "         [1.5687e-07, 1.5437e-08, 4.9097e-09,  ..., 0.0000e+00,\n",
       "          2.9548e-09, 1.4906e-09],\n",
       "         [9.5847e-08, 6.0000e-08, 3.1491e-09,  ..., 0.0000e+00,\n",
       "          4.6814e-09, 1.6034e-09],\n",
       "         [1.0769e-07, 2.4570e-08, 2.4332e-09,  ..., 0.0000e+00,\n",
       "          5.3183e-09, 1.7668e-09]],\n",
       "\n",
       "        [[0.0000e+00, 2.2209e-09, 2.3030e-08,  ..., 5.6443e-02,\n",
       "          0.0000e+00, 5.7043e-09],\n",
       "         [0.0000e+00, 1.8203e-09, 1.1619e-01,  ..., 1.2516e+00,\n",
       "          0.0000e+00, 5.7964e-09],\n",
       "         [0.0000e+00, 1.7494e-09, 1.4148e-08,  ..., 4.7185e-09,\n",
       "          0.0000e+00, 5.4098e-09],\n",
       "         ...,\n",
       "         [0.0000e+00, 2.6216e-10, 7.6420e-10,  ..., 1.2303e-08,\n",
       "          0.0000e+00, 3.7598e-09],\n",
       "         [0.0000e+00, 2.1278e-10, 8.7454e-10,  ..., 7.1726e-09,\n",
       "          0.0000e+00, 2.7347e-09],\n",
       "         [0.0000e+00, 1.6851e-10, 8.6309e-10,  ..., 3.4910e-09,\n",
       "          0.0000e+00, 2.2291e-09]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000e+00, 1.2516e-08, 0.0000e+00,  ..., 4.2611e-01,\n",
       "          7.8195e-02, 0.0000e+00],\n",
       "         [0.0000e+00, 6.5164e-09, 0.0000e+00,  ..., 4.5354e-09,\n",
       "          1.6446e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 7.6450e-09, 0.0000e+00,  ..., 5.2123e-09,\n",
       "          1.2373e-08, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 8.4556e-09, 0.0000e+00,  ..., 3.8740e-10,\n",
       "          3.4386e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 2.0878e-08, 0.0000e+00,  ..., 4.5942e-10,\n",
       "          1.7559e-08, 0.0000e+00],\n",
       "         [0.0000e+00, 1.3795e-08, 0.0000e+00,  ..., 5.0848e-10,\n",
       "          1.4517e-08, 0.0000e+00]],\n",
       "\n",
       "        [[2.0204e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.7233e-10],\n",
       "         [2.3917e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.6526e-10],\n",
       "         [2.3842e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.8572e-10],\n",
       "         ...,\n",
       "         [1.0107e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 8.6477e-10],\n",
       "         [1.1127e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.1044e-09],\n",
       "         [1.2327e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.3163e-09]],\n",
       "\n",
       "        [[1.0287e+00, 1.5075e-08, 1.4224e-08,  ..., 7.1451e-09,\n",
       "          0.0000e+00, 1.0094e+00],\n",
       "         [4.2108e-07, 2.5602e-08, 2.1620e-08,  ..., 3.8349e-09,\n",
       "          0.0000e+00, 2.5005e-01],\n",
       "         [1.4257e+00, 4.5474e-08, 1.1686e-08,  ..., 3.0073e-09,\n",
       "          0.0000e+00, 4.1244e-08],\n",
       "         ...,\n",
       "         [2.7018e-07, 1.0060e-08, 3.7548e-09,  ..., 7.7228e-08,\n",
       "          0.0000e+00, 4.7151e-08],\n",
       "         [1.4933e+00, 1.4357e-08, 6.2154e-09,  ..., 1.9153e-08,\n",
       "          0.0000e+00, 3.4917e-08],\n",
       "         [3.0220e-07, 1.9235e-08, 8.6368e-09,  ..., 1.0637e-08,\n",
       "          0.0000e+00, 2.3988e-08]]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes # zeros on the masked positions? -> literally put zeros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2438992, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(spikes== 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2438992, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_mask = time_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_mask = targets_mask.to(torch.int64) & spikes_mask.unsqueeze(-1).expand(B,_T,N).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 7908])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2438992, device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7908"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralStitcher(\n",
       "  (stitcher_dict): ModuleDict(\n",
       "    (7671): Linear(in_features=7671, out_features=668, bias=True)\n",
       "    (7495): Linear(in_features=7495, out_features=668, bias=True)\n",
       "    (8122): Linear(in_features=8122, out_features=668, bias=True)\n",
       "    (8202): Linear(in_features=8202, out_features=668, bias=True)\n",
       "    (7440): Linear(in_features=7440, out_features=668, bias=True)\n",
       "    (7908): Linear(in_features=7908, out_features=668, bias=True)\n",
       "    (7863): Linear(in_features=7863, out_features=668, bias=True)\n",
       "    (8285): Linear(in_features=8285, out_features=668, bias=True)\n",
       "    (7939): Linear(in_features=7939, out_features=668, bias=True)\n",
       "    (7928): Linear(in_features=7928, out_features=668, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.stitcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.2725e-08, 0.0000e+00, 8.6449e-09,  ..., 6.4939e-09,\n",
       "          1.9378e-08, 1.3059e-08],\n",
       "         [5.6876e-02, 0.0000e+00, 4.2500e-09,  ..., 7.1709e-09,\n",
       "          1.5093e-07, 1.3812e-08],\n",
       "         [1.3601e-07, 0.0000e+00, 2.9259e-09,  ..., 1.1829e+00,\n",
       "          1.6280e-01, 2.3847e-08],\n",
       "         ...,\n",
       "         [3.9993e-07, 0.0000e+00, 7.1607e-09,  ..., 3.7941e-09,\n",
       "          1.1166e-08, 8.5400e-08],\n",
       "         [7.5033e-01, 0.0000e+00, 1.1914e-08,  ..., 3.2651e-09,\n",
       "          5.3026e-09, 4.8186e-08],\n",
       "         [6.6764e-08, 0.0000e+00, 4.6936e-01,  ..., 3.1239e-09,\n",
       "          3.6501e-09, 1.8141e-08]],\n",
       "\n",
       "        [[3.7631e-08, 2.7802e-01, 5.6674e-09,  ..., 0.0000e+00,\n",
       "          6.2580e-10, 1.7016e-09],\n",
       "         [1.3292e-07, 7.2055e-08, 1.1955e-08,  ..., 0.0000e+00,\n",
       "          5.3072e-10, 1.8141e-09],\n",
       "         [2.2637e-07, 2.1218e-07, 1.4143e-08,  ..., 0.0000e+00,\n",
       "          4.9449e-10, 2.2268e-09],\n",
       "         ...,\n",
       "         [1.5687e-07, 1.5437e-08, 4.9097e-09,  ..., 0.0000e+00,\n",
       "          2.9548e-09, 1.4906e-09],\n",
       "         [9.5847e-08, 6.0000e-08, 3.1491e-09,  ..., 0.0000e+00,\n",
       "          4.6814e-09, 1.6034e-09],\n",
       "         [1.0769e-07, 2.4570e-08, 2.4332e-09,  ..., 0.0000e+00,\n",
       "          5.3183e-09, 1.7668e-09]],\n",
       "\n",
       "        [[0.0000e+00, 2.2209e-09, 2.3030e-08,  ..., 5.6443e-02,\n",
       "          0.0000e+00, 5.7043e-09],\n",
       "         [0.0000e+00, 1.8203e-09, 1.1619e-01,  ..., 1.2516e+00,\n",
       "          0.0000e+00, 5.7964e-09],\n",
       "         [0.0000e+00, 1.7494e-09, 1.4148e-08,  ..., 4.7185e-09,\n",
       "          0.0000e+00, 5.4098e-09],\n",
       "         ...,\n",
       "         [0.0000e+00, 2.6216e-10, 7.6420e-10,  ..., 1.2303e-08,\n",
       "          0.0000e+00, 3.7598e-09],\n",
       "         [0.0000e+00, 2.1278e-10, 8.7454e-10,  ..., 7.1726e-09,\n",
       "          0.0000e+00, 2.7347e-09],\n",
       "         [0.0000e+00, 1.6851e-10, 8.6309e-10,  ..., 3.4910e-09,\n",
       "          0.0000e+00, 2.2291e-09]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000e+00, 1.2516e-08, 0.0000e+00,  ..., 4.2611e-01,\n",
       "          7.8195e-02, 0.0000e+00],\n",
       "         [0.0000e+00, 6.5164e-09, 0.0000e+00,  ..., 4.5354e-09,\n",
       "          1.6446e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 7.6450e-09, 0.0000e+00,  ..., 5.2123e-09,\n",
       "          1.2373e-08, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 8.4556e-09, 0.0000e+00,  ..., 3.8740e-10,\n",
       "          3.4386e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 2.0878e-08, 0.0000e+00,  ..., 4.5942e-10,\n",
       "          1.7559e-08, 0.0000e+00],\n",
       "         [0.0000e+00, 1.3795e-08, 0.0000e+00,  ..., 5.0848e-10,\n",
       "          1.4517e-08, 0.0000e+00]],\n",
       "\n",
       "        [[2.0204e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.7233e-10],\n",
       "         [2.3917e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.6526e-10],\n",
       "         [2.3842e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.8572e-10],\n",
       "         ...,\n",
       "         [1.0107e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 8.6477e-10],\n",
       "         [1.1127e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.1044e-09],\n",
       "         [1.2327e-08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.3163e-09]],\n",
       "\n",
       "        [[1.0287e+00, 1.5075e-08, 1.4224e-08,  ..., 7.1451e-09,\n",
       "          0.0000e+00, 1.0094e+00],\n",
       "         [4.2108e-07, 2.5602e-08, 2.1620e-08,  ..., 3.8349e-09,\n",
       "          0.0000e+00, 2.5005e-01],\n",
       "         [1.4257e+00, 4.5474e-08, 1.1686e-08,  ..., 3.0073e-09,\n",
       "          0.0000e+00, 4.1244e-08],\n",
       "         ...,\n",
       "         [2.7018e-07, 1.0060e-08, 3.7548e-09,  ..., 7.7228e-08,\n",
       "          0.0000e+00, 4.7151e-08],\n",
       "         [1.4933e+00, 1.4357e-08, 6.2154e-09,  ..., 1.9153e-08,\n",
       "          0.0000e+00, 3.4917e-08],\n",
       "         [3.0220e-07, 1.9235e-08, 8.6368e-09,  ..., 1.0637e-08,\n",
       "          0.0000e+00, 2.3988e-08]]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2438992, device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(spikes== 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mew\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model.encoder, 'stitcher'):\n",
    "    spikes = model.encoder.stitcher(spikes, str(num_neuron))\n",
    "    print('mew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, device='cuda:0'), torch.Size([64, 16, 668]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(spikes== 0).sum(), spikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = None\n",
    "date_idx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, spikes_mask, spikes_timestamp = model.encoder.embedder(\n",
    "    spikes, spikes_mask, spikes_timestamps, block_idx, date_idx, targets_mask, masking_mode, eid\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 17, 512])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 17])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, device='cuda:0'), tensor(1088, device='cuda:0'), 1088)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(spikes_mask == 0).sum(), spikes_mask.sum(), 64*17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 17])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_timestamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spikes, \n",
    "time_attn_mask, \n",
    "spikes_timestamps, \n",
    "block_idx, \n",
    "date_idx, \n",
    "neuron_regions, \n",
    "masking_mode, \n",
    "eval_mask, \n",
    "num_neuron, \n",
    "eid)\n",
    "\n",
    "\n",
    "spikes:           torch.FloatTensor,  # (bs, seq_len, n_channels)\n",
    "spikes_mask:      torch.LongTensor,   # (bs, seq_len)\n",
    "spikes_timestamp: torch.LongTensor,   # (bs, seq_len)\n",
    "block_idx:        Optional[torch.LongTensor] = None,   # (bs)\n",
    "date_idx:         Optional[torch.LongTensor] = None,   # (bs)\n",
    "neuron_regions:   Optional[np.ndarray] = None,  # (bs, n_channels)\n",
    "masking_mode:     Optional[str] = None,\n",
    "eval_mask:        Optional[torch.LongTensor] = None,\n",
    "num_neuron:       Optional[torch.LongTensor] = None,\n",
    "eid:              Optional[str] = None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = accelerator.prepare(model)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(\n",
    "#     model.parameters(),\n",
    "#     lr=config.optimizer.lr,\n",
    "#     weight_decay=config.optimizer.wd,\n",
    "#     eps=config.optimizer.eps,\n",
    "# )\n",
    "# lr_scheduler = OneCycleLR(\n",
    "#     optimizer=optimizer,\n",
    "#     total_steps=config.training.num_epochs * len(train_dataloader) // config.optimizer.gradient_accumulation_steps,\n",
    "#     max_lr=config.optimizer.lr,\n",
    "#     pct_start=config.optimizer.warmup_pct,\n",
    "#     div_factor=config.optimizer.div_factor,\n",
    "# )\n",
    "\n",
    "# trainer_kwargs = {\n",
    "#     \"log_dir\": log_dir,\n",
    "#     \"accelerator\": accelerator,\n",
    "#     \"lr_scheduler\": lr_scheduler,\n",
    "#     \"config\": config,\n",
    "#     \"stitching\": config.encoder.stitching,\n",
    "# }\n",
    "\n",
    "# trainer = make_trainer(\n",
    "#     model=model,\n",
    "#     train_dataloader=train_dataloader,\n",
    "#     eval_dataloader=val_dataloader,\n",
    "#     optimizer=optimizer,\n",
    "#     **trainer_kwargs,\n",
    "#     **meta_data\n",
    "# )\n",
    "# Shared variable to signal the dummy load to stop\n",
    "stop_dummy_load = threading.Event()\n",
    "if config.training.dummy:\n",
    "    # This is for HPC GPU usage, to avoid the GPU being idle\n",
    "    print(\"Running dummy load\")\n",
    "    # Run dummy load in a separate thread\n",
    "    dummy_thread = threading.Thread(target=dummy_load, args=(stop_dummy_load,))\n",
    "    dummy_thread.start()\n",
    "    try:\n",
    "        # train loop\n",
    "        trainer.train()\n",
    "    finally:\n",
    "        # Signal the dummy load to stop and wait for the thread to finish\n",
    "        stop_dummy_load.set()\n",
    "        dummy_thread.join()\n",
    "else:\n",
    "    # train loop\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibl-fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
